[{"content":" Katacoda在线课：https://www.katacoda.com/courses/kubernetes/kubectl-run-containers\n本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。\n 在此场景中，将学习如何使用 Kubectl 创建和启动Deployments, Replication Controllers并通过Services对外开放接口，而无需编写 yaml 定义。这样便可以快速将容器启动到集群上。\n启动集群 首先，我们需要启动一个 Kubernetes 集群。\n执行以下命令启动集群并下载Kubectl CLI。\n$ minikube start --wait=false * minikube v1.8.1 on Ubuntu 18.04 * Using the none driver based on user configuration * Running on localhost (CPUs=2, Memory=2460MB, Disk=145651MB) ... * OS release is Ubuntu 18.04.4 LTS * Preparing Kubernetes v1.17.3 on Docker 19.03.6 ... - kubelet.resolv-conf=/run/systemd/resolve/resolv.conf * Launching Kubernetes ... * Enabling addons: default-storageclass, storage-provisioner * Configuring local host environment ... * Done! kubectl is now configured to use \u0026#34;minikube\u0026#34; 通过kubectl get nodes命令来检查节点是否准备就绪。\n$ kubectl get nodes NAME STATUS ROLES AGE VERSION minikube Ready master 19s v1.17.3 Kubectl Run Run 命令根据指定的参数（例如映像或副本）创建部署。该部署发布给Kubernetes 主节点，启动所需 Pod 和容器的 。 Kubectl run 类似于 docker run，但Kubectl run 是在集群中运行的。\n命令的格式为 kubectl run \u0026lt;name of deployment\u0026gt; \u0026lt;properties\u0026gt;\n任务 以下命令将启动一个名为 http 的部署，它将启动一个基于 Docker 镜像 katacoda/docker-http-server:latest 的容器。\n$ kubectl run http --image=katacoda/docker-http-server:latest --replicas=1 kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. deployment.apps/http created 使用kubectl查看各部署的状态。\n$ kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE http 1/1 1 1 2m7s 可以通过 describe 查看 Kubernetes 创建了哪些内容。\n$ kubectl describe deployment http Name: http Namespace: default CreationTimestamp: Wed, 21 Jul 2021 08:04:55 +0000 Labels: run=http Annotations: deployment.kubernetes.io/revision: 1 Selector: run=http Replicas: 1 desired | 1 updated | 1 total | 1 available | 0 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 25% max unavailable, 25% max surge Pod Template: Labels: run=http Containers: http: Image: katacoda/docker-http-server:latest Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; Environment: \u0026lt;none\u0026gt; Mounts: \u0026lt;none\u0026gt; Volumes: \u0026lt;none\u0026gt; Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable OldReplicaSets: \u0026lt;none\u0026gt; NewReplicaSet: http-774bb756bb (1/1 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 4m16s deployment-controller Scaled up replica set http-774bb756bb to 1 描述中包含有多少副本可用、指定的标签以及与部署相关的事件等信息。这些事件将突出显示可能发生的任何问题和错误。\n在下一步中，我们将开放正在运行的服务。\nKubectl Expose 创建部署后，我们可以使用 kubectl 创建一个服务，该服务在特定端口上开放 Pod。\n通过 kubectl expose 开放新部署的 http 部署。该命令允许定义服务的不同参数以及如何开放该部署。\n任务 使用以下命令将主机上的容器端口 80 公开 8000 绑定到主机的 external-ip。\n$ kubectl expose deployment http --external-ip=\u0026#34;172.17.0.44\u0026#34; --port=8000 --target-port=80 service/http exposed 接下来就能 ping 主机查看 HTTP 服务返回的结果。\n$ curl http://172.17.0.44:8000 \u0026lt;h1\u0026gt;This request was processed by host: http-774bb756bb-m6tjp\u0026lt;/h1\u0026gt; Kubectl Run and Expose 可以单独使用命令 kubectl run 来创建部署并将其开放。\n任务 使用命令创建在端口 8001 上开放的第二个 http 服务。\n$ kubectl run httpexposed --image=katacoda/docker-http-server:latest --replicas=1 --port=80 --hostport=8001 kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. deployment.apps/httpexposed created 接下来可以使用 curl http://172.17.0.41:8001 来访问该服务。\n$ curl http://172.17.0.44:8001 \u0026lt;h1\u0026gt;This request was processed by host: httpexposed-68cb8c8d4-r7qtt\u0026lt;/h1\u0026gt; 在服务内，通过 Docker 端口映射开放了 Pod。因此，您将看不到使用 kubectl get svc 列出的服务\n$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE http ClusterIP 10.97.103.237 172.17.0.44 8000/TCP 4m47s kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 44m 可以通过 docker ps | grep httpexposed命令查看详细信息。\n$ docker ps | grep httpexposed 1690c6682f93 katacoda/docker-http-server \u0026#34;/app\u0026#34; 2 minutes ago Up 2 minutes k8s_httpexposed_httpexposed-68cb8c8d4-r7qtt_default_6fb23c14-277e-4298-b325-c52ef4eb09a9_0 d9ae0076a0d4 k8s.gcr.io/pause:3.1 \u0026#34;/pause\u0026#34; 2 minutes ago Up 2 minutes 0.0.0.0:8001-\u0026gt;80/tcp k8s_POD_httpexposed-68cb8c8d4-r7qtt_default_6fb23c14-277e-4298-b325-c52ef4eb09a9_0 暂停容器 运行上面的命令，你会注意到端口暴露在 Pod 上，而不是 http 容器本身。 Pause 容器负责为 Pod 定义网络。 Pod 中的其他容器共享相同的网络命名空间。允许多个容器通过同一网络接口进行通信，提高了网络性能。\n容器扩展 随着我们的部署运行，我们现在可以使用 kubectl 来扩展副本的数量。\n扩展部署将请求 Kubernetes 启动额外的 Pod。然后，这些 Pod 将使用开放服务自动进行负载平衡。\n任务 kubectl scale 命令能够为特定 Deployment或 Replication Controller 调整运行的 Pod 数量。\n$ kubectl scale --replicas=3 deployment http deployment.apps/http scaled 列出所有 pod，能够看到三个正在运行的 http 部署。\n$ kubectl get pods NAME READY STATUS RESTARTS AGE http-774bb756bb-m6tjp 1/1 Running 0 20m http-774bb756bb-q29v8 1/1 Running 0 45s http-774bb756bb-x2xxv 1/1 Running 0 45s httpexposed-68cb8c8d4-r7qtt 1/1 Running 0 9m3s 一旦每个 Pod 启动，就会被添加到负载均衡器服务中。通过describe，可以查看包含的端点和与之关联的 Pod。 Once each Pod starts it will be added to the load balancer service. By describing the service you can view the endpoint and the associated Pods which are included.\n$ kubectl describe svc http Name: http Namespace: default Labels: run=http Annotations: \u0026lt;none\u0026gt; Selector: run=http Type: ClusterIP IP: 10.97.103.237 External IPs: 172.17.0.44 Port: \u0026lt;unset\u0026gt; 8000/TCP TargetPort: 80/TCP Endpoints: 172.18.0.4:80,172.18.0.6:80,172.18.0.7:80 Session Affinity: None Events: \u0026lt;none\u0026gt; 向服务发出多次请求，可以通过返回信息看出请求将在不同的节点处理。\n$ curl http://172.17.0.44:8000 \u0026lt;h1\u0026gt;This request was processed by host: http-774bb756bb-x2xxv\u0026lt;/h1\u0026gt; $ curl http://172.17.0.44:8000 \u0026lt;h1\u0026gt;This request was processed by host: http-774bb756bb-q29v8\u0026lt;/h1\u0026gt; $ curl http://172.17.0.44:8000 \u0026lt;h1\u0026gt;This request was processed by host: http-774bb756bb-q29v8\u0026lt;/h1\u0026gt; $ curl http://172.17.0.44:8000 \u0026lt;h1\u0026gt;This request was processed by host: http-774bb756bb-x2xxv\u0026lt;/h1\u0026gt; $ curl http://172.17.0.44:8000 \u0026lt;h1\u0026gt;This request was processed by host: http-774bb756bb-q29v8\u0026lt;/h1\u0026gt; $ curl http://172.17.0.44:8000 \u0026lt;h1\u0026gt;This request was processed by host: http-774bb756bb-q29v8\u0026lt;/h1\u0026gt; $ curl http://172.17.0.44:8000 \u0026lt;h1\u0026gt;This request was processed by host: http-774bb756bb-m6tjp\u0026lt;/h1\u0026gt; $ curl http://172.17.0.44:8000 \u0026lt;h1\u0026gt;This request was processed by host: http-774bb756bb-x2xxv\u0026lt;/h1\u0026gt; ","date":"2021-07-20T11:27:00+08:00","image":"https://www.catfish.top/p/k8s-basic-3/kubernates_hu999cd8b4a0602898549f5ade1550b92a_32166_120x120_fill_box_smart1_2.png","permalink":"https://www.catfish.top/p/k8s-basic-3/","title":"Kubernetes初探（三）"},{"content":" Katacoda在线课：https://www.katacoda.com/courses/kubernetes/getting-started-with-kubeadm\n本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。\n 在此场景中，您将学习如何使用 Kubeadm 启动 Kubernetes 集群。\nKubeadm 解决了TLS 加密配置、 Kubernetes 核心组件部署和额外节点集群加入的问题。启动的集群通过 RBAC 等机制开箱即用。\n关于Kubeadm的更多信息可以参考： https://github.com/kubernetes/kubeadm\n初始化 Master Kubeadm 已经安装在节点上。软件包适用于 Ubuntu 16.04+、CentOS 7 或 HypriotOS v1.0.1+。\n初始化集群的第一步是启动Master节点。 Master节点 负责运行控制平面组件、etcd 和 API 服务器。客户端能够与 API 通信，能够完成工作负载的调度和集群状态的管理。\n任务 下面的命令将使用已知的Token简化初始化集群的步骤。\ncontrolplane $ kubeadm init --token=102952.1a7dd4cc8d1f4cc5 --kubernetes-version $(kubeadm version -o short) [init] Using Kubernetes version: v1.14.0 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using \u0026#39;kubeadm config images pull\u0026#39; [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Activating the kubelet service [certs] Using certificateDir folder \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Generating \u0026#34;etcd/ca\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/healthcheck-client\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/server\u0026#34; certificate and key [certs] etcd/server serving cert is signed for DNS names [controlplane localhost] and IPs [172.17.0.86 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/peer\u0026#34; certificate and key [certs] etcd/peer serving cert is signed for DNS names [controlplane localhost] and IPs [172.17.0.86 127.0.0.1 ::1] [certs] Generating \u0026#34;apiserver-etcd-client\u0026#34; certificate and key [certs] Generating \u0026#34;ca\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver\u0026#34; certificate and key [certs] apiserver serving cert is signed for DNS names [controlplane kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.17.0.86] [certs] Generating \u0026#34;apiserver-kubelet-client\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-ca\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-client\u0026#34; certificate and key [certs] Generating \u0026#34;sa\u0026#34; key and public key [kubeconfig] Using kubeconfig folder \u0026#34;/etc/kubernetes\u0026#34; [kubeconfig] Writing \u0026#34;admin.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;kubelet.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;controller-manager.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;scheduler.conf\u0026#34; kubeconfig file [control-plane] Using manifest folder \u0026#34;/etc/kubernetes/manifests\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-apiserver\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-controller-manager\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-scheduler\u0026#34; [etcd] Creating static Pod manifest for local etcd in \u0026#34;/etc/kubernetes/manifests\u0026#34; [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \u0026#34;/etc/kubernetes/manifests\u0026#34;. This can take up to 4m0s [apiclient] All control plane components are healthy after 17.503676 seconds [upload-config] storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.14\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --experimental-upload-certs [mark-control-plane] Marking the node controlplane as control-plane by adding the label \u0026#34;node-role.kubernetes.io/master=\u0026#39;\u0026#39;\u0026#34; [mark-control-plane] Marking the node controlplane as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: 102952.1a7dd4cc8d1f4cc5 [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] creating the \u0026#34;cluster-info\u0026#34; ConfigMap in the \u0026#34;kube-public\u0026#34; namespace [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 172.17.0.86:6443 --token 102952.1a7dd4cc8d1f4cc5 \\  --discovery-token-ca-cert-hash sha256:ab56a643a2d683bc1deeb483f0f946d4a774c4 在生产环境中，建议排除使用 kubeadm 生成的令牌。\n需要客户端配置和证书来管理 Kubernetes 集群。这个配置是在 kubeadm 初始化集群时创建的。该命令将配置复制到用户主目录并设置用于 CLI 的环境变量。\ncontrolplane $ sudo cp /etc/kubernetes/admin.conf $HOME/ controlplane $ sudo chown $(id -u):$(id -g) $HOME/admin.conf controlplane $ export KUBECONFIG=$HOME/admin.conf 部署容器网络接口 Container Networking Interface (CNI) 容器网络接口 (CNI) 定义了不同节点及其工作负载是如何通信的。有多个网络提供商可用，其中一些在 here 中列出。\n任务 在这个场景中，我们将使用 WeaveWorks的CNI。\n/opt/weave-kube.yaml 可以通过cat /opt/weave-kube.yaml命令查看部署定义。\napiVersion:v1kind:Listitems:- apiVersion:v1kind:ServiceAccountmetadata:name:weave-netannotations:cloud.weave.works/launcher-info:|-{ \u0026#34;original-request\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;/k8s/v1.10/net.yaml?k8s-version=v1.16.0\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;Mon Oct 28 2019 18:38:09 GMT+0000 (UTC)\u0026#34; }, \u0026#34;email-address\u0026#34;: \u0026#34;support@weave.works\u0026#34; }labels:name:weave-netnamespace:kube-system- apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRolemetadata:name:weave-netannotations:cloud.weave.works/launcher-info:|-{ \u0026#34;original-request\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;/k8s/v1.10/net.yaml?k8s-version=v1.16.0\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;Mon Oct 28 2019 18:38:09 GMT+0000 (UTC)\u0026#34; }, \u0026#34;email-address\u0026#34;: \u0026#34;support@weave.works\u0026#34; }labels:name:weave-netrules:- apiGroups:- \u0026#39;\u0026#39;resources:- pods- namespaces- nodesverbs:- get- list- watch- apiGroups:- networking.k8s.ioresources:- networkpoliciesverbs:- get- list- watch- apiGroups:- \u0026#39;\u0026#39;resources:- nodes/statusverbs:- patch- update- apiVersion:rbac.authorization.k8s.io/v1kind:ClusterRoleBindingmetadata:name:weave-netannotations:cloud.weave.works/launcher-info:|-{ \u0026#34;original-request\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;/k8s/v1.10/net.yaml?k8s-version=v1.16.0\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;Mon Oct 28 2019 18:38:09 GMT+0000 (UTC)\u0026#34; }, \u0026#34;email-address\u0026#34;: \u0026#34;support@weave.works\u0026#34; }labels:name:weave-netroleRef:kind:ClusterRolename:weave-netapiGroup:rbac.authorization.k8s.iosubjects:- kind:ServiceAccountname:weave-netnamespace:kube-system- apiVersion:rbac.authorization.k8s.io/v1kind:Rolemetadata:name:weave-netannotations:cloud.weave.works/launcher-info:|-{ \u0026#34;original-request\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;/k8s/v1.10/net.yaml?k8s-version=v1.16.0\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;Mon Oct 28 2019 18:38:09 GMT+0000 (UTC)\u0026#34; }, \u0026#34;email-address\u0026#34;: \u0026#34;support@weave.works\u0026#34; }labels:name:weave-netnamespace:kube-systemrules:- apiGroups:- \u0026#39;\u0026#39;resourceNames:- weave-netresources:- configmapsverbs:- get- update- apiGroups:- \u0026#39;\u0026#39;resources:- configmapsverbs:- create- apiVersion:rbac.authorization.k8s.io/v1kind:RoleBindingmetadata:name:weave-netannotations:cloud.weave.works/launcher-info:|-{ \u0026#34;original-request\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;/k8s/v1.10/net.yaml?k8s-version=v1.16.0\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;Mon Oct 28 2019 18:38:09 GMT+0000 (UTC)\u0026#34; }, \u0026#34;email-address\u0026#34;: \u0026#34;support@weave.works\u0026#34; }labels:name:weave-netnamespace:kube-systemroleRef:kind:Rolename:weave-netapiGroup:rbac.authorization.k8s.iosubjects:- kind:ServiceAccountname:weave-netnamespace:kube-system- apiVersion:apps/v1kind:DaemonSetmetadata:name:weave-netannotations:cloud.weave.works/launcher-info:|-{ \u0026#34;original-request\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;/k8s/v1.10/net.yaml?k8s-version=v1.16.0\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;Mon Oct 28 2019 18:38:09 GMT+0000 (UTC)\u0026#34; }, \u0026#34;email-address\u0026#34;: \u0026#34;support@weave.works\u0026#34; }labels:name:weave-netnamespace:kube-systemspec:minReadySeconds:5selector:matchLabels:name:weave-nettemplate:metadata:labels:name:weave-netspec:containers:- name:weavecommand:- /home/weave/launch.shenv:- name:IPALLOC_RANGEvalue:10.32.0.0/24- name:HOSTNAMEvalueFrom:fieldRef:apiVersion:v1fieldPath:spec.nodeNameimage:\u0026#39;docker.io/weaveworks/weave-kube:2.6.0\u0026#39;readinessProbe:httpGet:host:127.0.0.1path:/statusport:6784resources:requests:cpu:10msecurityContext:privileged:truevolumeMounts:- name:weavedbmountPath:/weavedb- name:cni-binmountPath:/host/opt- name:cni-bin2mountPath:/host/home- name:cni-confmountPath:/host/etc- name:dbusmountPath:/host/var/lib/dbus- name:lib-modulesmountPath:/lib/modules- name:xtables-lockmountPath:/run/xtables.lock- name:weave-npcenv:- name:HOSTNAMEvalueFrom:fieldRef:apiVersion:v1fieldPath:spec.nodeNameimage:\u0026#39;docker.io/weaveworks/weave-npc:2.6.0\u0026#39;resources:requests:cpu:10msecurityContext:privileged:truevolumeMounts:- name:xtables-lockmountPath:/run/xtables.lockhostNetwork:truehostPID:truerestartPolicy:AlwayssecurityContext:seLinuxOptions:{}serviceAccountName:weave-nettolerations:- effect:NoScheduleoperator:Existsvolumes:- name:weavedbhostPath:path:/var/lib/weave- name:cni-binhostPath:path:/opt- name:cni-bin2hostPath:path:/home- name:cni-confhostPath:path:/etc- name:dbushostPath:path:/var/lib/dbus- name:lib-moduleshostPath:path:/lib/modules- name:xtables-lockhostPath:path:/run/xtables.locktype:FileOrCreateupdateStrategy:type:RollingUpdate使用kubectl apply命令来完成部署工作。.\ncontrolplane $ kubectl apply -f /opt/weave-kube.yaml serviceaccount/weave-net created clusterrole.rbac.authorization.k8s.io/weave-net created clusterrolebinding.rbac.authorization.k8s.io/weave-net created role.rbac.authorization.k8s.io/weave-net created rolebinding.rbac.authorization.k8s.io/weave-net created daemonset.apps/weave-net created Weave 现在将在集群上部署为一系列的 Pod。 可以通过 kubectl get pod -n kube-system命令查看状态。\ncontrolplane $ kubectl get pod -n kube-system NAME READY STATUS RESTARTS AGE coredns-fb8b8dccf-gw8z6 1/1 Running 0 12m coredns-fb8b8dccf-qzd49 1/1 Running 0 12m etcd-controlplane 1/1 Running 0 12m kube-apiserver-controlplane 1/1 Running 0 11m kube-controller-manager-controlplane 1/1 Running 0 11m kube-proxy-2kjsl 1/1 Running 0 13m kube-scheduler-controlplane 1/1 Running 1 11m weave-net-2dtbs 2/2 Running 0 82s 需要安装Weave在你的集群中时，可以在 https://www.weave.works/docs/net/latest/kube-addon/ 找到更多详细信息。\n加入集群 一旦 Master 和 CNI 初始化完成，其他节点只要拥有正确的令牌就可以加入集群。令牌可以通过 kubeadm token 进行管理，例如 kubeadm token list。\ncontrolplane $ kubeadm token list TOKEN TTL EXPIRES USAGES DESCRIPTION EXTRA GROUPS 102952.1a7dd4cc8d1f4cc5 23h 2021-07-21T10:00:20Z authentication,signing The default bootstrap token generated by \u0026#39;kubeadm init\u0026#39;. system:bootstrappers:kubeadm:default-node-token 任务 在第二个节点上，使用主节点的 IP 地址，运行命令加入集群。\nnode01 $ kubeadm join --discovery-token-unsafe-skip-ca-verification --token=102952.1a7dd4cc8d1f4cc5 172.17.0.86:6443 [preflight] Running pre-flight checks [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [kubelet-start] Downloading configuration for the kubelet from the \u0026quot;kubelet-config-1.14\u0026quot; ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file \u0026quot;/var/lib/kubelet/config.yaml\u0026quot; [kubelet-start] Writing kubelet environment file with flags to file \u0026quot;/var/lib/kubelet/kubeadm-flags.env\u0026quot; [kubelet-start] Activating the kubelet service [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run 'kubectl get nodes' on the control-plane to see this node join the cluster. Node01节点与 Master 节点初始化提供的命令相同。\n--discovery-token-unsafe-skip-ca-verification 标签用于绕过 Discovery Token 验证。由于此令牌是动态生成的，因此我们无法将其包含在步骤中。在生产环境中，使用 kubeadm init 提供的令牌。\n查看节点 集群现已初始化。主节点将负责管理集群，另一个工作节点将负责运行我们的容器工作负载。\n任务 Kubernetes CLI，称为 kubectl，现在可以使用配置访问集群。例如，下面的命令将返回我们集群中的两个节点信息。\ncontrolplane $ kubectl get nodes NAME STATUS ROLES AGE VERSION controlplane Ready master 25m v1.14.0 node01 Ready \u0026lt;none\u0026gt; 2m v1.14.0 部署 Pod 集群中两个节点的状态现在应该是 Ready。这表示接下来可以进行调度和启动部署。\n使用 Kubectl，可以部署 Pod。命令总是由 Master 发出，每个节点只负责运行工作负载。\n下面的命令是基于 Docker 镜像 katacoda/docker-http-server 创建一个 Pod。\ncontrolplane $ kubectl create deployment http --image=katacoda/docker-http-server:latest deployment.apps/http created 可以使用kubectl get pods查看Pod创建的状态\ncontrolplane $ kubectl get pods NAME READY STATUS RESTARTS AGE http-7f8cbdf584-jcdrj 1/1 Running 0 70s 运行后，可以看到节点上Docker 容器的运行状态。\nnode01 $ docker ps | grep docker-http-server d874d8c3151b katacoda/docker-http-server \u0026quot;/app\u0026quot; About a minute ago Up About a minute k8s_docker-http-server_http-7f8cbdf584-jcdrj_default_2894ce10-e945-11eb-b87f-0242ac110056_0 部署仪表盘 Kubernetes 有一个基于 Web 的仪表板应用，提供对 Kubernetes 集群的查看与管理能力。\n任务 使用 kubectl apply -f dashboard.yaml 命令部署仪表板。\ncontrolplane $ kubectl apply -f dashboard.yaml secret/kubernetes-dashboard-certs created serviceaccount/kubernetes-dashboard created role.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created deployment.apps/kubernetes-dashboard created service/kubernetes-dashboard created 仪表板将部署到 kube-system 命名空间中。使用 kubectl get pods -n kube-system命令 查看部署状态。\ncontrolplane $ kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-fb8b8dccf-rjzxp 1/1 Running 1 88s coredns-fb8b8dccf-tw8cm 1/1 Running 1 88s etcd-controlplane 1/1 Running 0 16s kube-apiserver-controlplane 1/1 Running 0 23s kube-controller-manager-controlplane 1/1 Running 1 61s kube-proxy-6xv6k 1/1 Running 0 84s kube-proxy-fn84g 1/1 Running 0 88s kube-scheduler-controlplane 1/1 Running 2 61s kubernetes-dashboard-5f57845f9d-jblx7 1/1 Running 0 5s weave-net-6gcbd 2/2 Running 1 88s weave-net-8s6bt 2/2 Running 1 84s 需要 ServiceAccount 才能登录。 ClusterRoleBinding 用于为新的 ServiceAccount (admin-user) 分配集群上的 cluster-admin 角色。\ncat \u0026lt;\u0026lt;EOF | kubectl create -f - apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kube-system EOF Dashboard可以控制 Kubernetes 的所有方面。通过 ClusterRoleBinding 和 RBAC，可以根据安全要求来定义不同级别的权限。有关为仪表板创建用户的更多信息，请参考 Dashboard documentation。\n创建 ServiceAccount 后，可以通过以下方式获取登录令牌：\ncontrolplane $ kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk \u0026#39;{print $1}\u0026#39;) Name: attachdetach-controller-token-bltlp Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: attachdetach-controller kubernetes.io/service-account.uid: 0ced9bf4-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhdHRhY2hkZXRhY2gtY29udHJvbGxlci10b2tlbi1ibHRscCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJhdHRhY2hkZXRhY2gtY29udHJvbGxlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBjZWQ5YmY0LWU5ZDQtMTFlYi1iMjViLTAyNDJhYzExMDAwOSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTphdHRhY2hkZXRhY2gtY29udHJvbGxlciJ9.x0a2m2SpBrwj8sARrvRfuct2ghrDydxYzyFmDL93hATdS_59zaueB4SrgHner8gOu_zrx9PLWcSoZNBxRblZuxJj8Di9TKUTjyDBE6txc4_0H8nseuQzljvRTbjUjEcL7fp8H1j4MrJgT4GrYU-n1gAOl6NIfk8FmpFpuUUS6G_IfIDfS60YpZRlqZGp14NuaL0RC71PsERnP6ZYnuRKTbYNfVNeURqVR4pY7XwCcQZFALaJcTf9SgwJLAAqLQFgKd9c2MYnHdnU5cnqjrYxi_b5kGBKUcRzACrHjh0uGG6ErHeo6-GbA-0NDdIMI7qKa3If0oh_GOQKmyB5cyx-Rw Name: bootstrap-signer-token-cstqm Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: bootstrap-signer kubernetes.io/service-account.uid: 0dc1b223-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJib290c3RyYXAtc2lnbmVyLXRva2VuLWNzdHFtIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImJvb3RzdHJhcC1zaWduZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwZGMxYjIyMy1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06Ym9vdHN0cmFwLXNpZ25lciJ9.hkciM9KpWYYPyi5MJbm67oqzuskjDB_Rj4Fz5THhtN_jJAO6go4oxz-NPparOi7kxaEU0yBLb_xLY42jOXvG_Q2Dd6gR2u9yc7nfwr67koW3lck4S0PCYSuGo-FqUndXS1a3BpT5SFAHhb52FdwEYiedevLz9C5wUDT8sVgMYSnHvEX_jwBmjrhhOohGxTNs_-_HyGMNNLfEOSbjaEtzkDFos0n3qPAJ95uaGKJ2laDsctVpHCeRx5hNCv8E7dvvR1Qp4XXDVDQrodkzkuG4LSKviYLzMLX1DM2XES3HQ7Q2uTtAICqxIDBjRlhfAPv_z02tqAbCf4fF6_CFlYK1ag Name: bootstrap-token-102952 Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Type: bootstrap.kubernetes.io/token Data ==== token-secret: 16 bytes usage-bootstrap-authentication: 4 bytes usage-bootstrap-signing: 4 bytes auth-extra-groups: 47 bytes description: 56 bytes expiration: 20 bytes token-id: 6 bytes Name: certificate-controller-token-mw9rl Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: certificate-controller kubernetes.io/service-account.uid: 0cf891ba-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjZXJ0aWZpY2F0ZS1jb250cm9sbGVyLXRva2VuLW13OXJsIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImNlcnRpZmljYXRlLWNvbnRyb2xsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwY2Y4OTFiYS1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06Y2VydGlmaWNhdGUtY29udHJvbGxlciJ9.NIZpVmhuJUcrpbZJApUt7ODgqIPU9RN4UZcr6he83xA_66-4ORQVddj1oQQg4G0p4fSPckWfP0n7pSxahZ90VZ-NCxPeCVLThLZ563PUOIljsjfROgFLQ4eeWfRML0OHyhAgoTtfEdcHi4_IzyhSrvCOweM9oPFfdx9MdTNAG9znyQsCi4g1YNHwn7t4r8h-BouW4yRYMEOM9HVZkcDVWhmF9PDv9s235INvIAjco5JvCAeDKvw48hdSrm4RWQPmZ7yE71iBDymDF_Ntr9w12H_4FPOYcARfFOmIj1k5binKiHaOlWtfbKYGYFM4tAxqI-ErFx4lshkLNJm3ICMJSQ Name: clusterrole-aggregation-controller-token-xh52b Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: clusterrole-aggregation-controller kubernetes.io/service-account.uid: 0acea7db-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjbHVzdGVycm9sZS1hZ2dyZWdhdGlvbi1jb250cm9sbGVyLXRva2VuLXhoNTJiIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImNsdXN0ZXJyb2xlLWFnZ3JlZ2F0aW9uLWNvbnRyb2xsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwYWNlYTdkYi1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06Y2x1c3RlcnJvbGUtYWdncmVnYXRpb24tY29udHJvbGxlciJ9.SgSxj_9uNLbAU9zYK4sTUYL4STx9CSYflGe0GwqGz_f3K7Db5NhpCuCoCcLYVJ7I2xogXICDJV016ZaNEAKJHWNJNeO-Ye378zjgddYmLAxX0uNw9OfSSiHKq-ksHgkKmoxwixgzVw2Df6PZGeYrKZZMSGuW96hkzd5JJx9Jhg2c4k8Fpqcpg5t-N4F5ZC8Ix4THpOmBueB8BaKox6OS5kUxqBAmdkJxZur1Wl8BvJV3Pnl6qbzYa0oPqun6N-WckGjVLrOlll1E6moABT1i8udZeRSrsX7YjjWgnbVyuyP0vzY7T1OQz-jcS0Lw3shMSIeANpwfFFB5XNvacsIV9A Name: coredns-token-z5tnd Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: coredns kubernetes.io/service-account.uid: 0ce34e5b-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjb3JlZG5zLXRva2VuLXo1dG5kIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImNvcmVkbnMiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwY2UzNGU1Yi1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06Y29yZWRucyJ9.vTVtFW7YZ-_dxjyiHjrkJnxyw3Q1c2oy43wEfs71tnD5GIDcXjioGXRn4OFvGJYzUzSM7fujZy6e6lXUDZBx-PkiRZzaqbxZTuY1skfTKdAm31h6xbOESSvuFcR97eASVMv5WNdFNSXZik4P3_pEoF7XUKnOnY-o3nk-MZNWRhmdcOvj-BhBmTqXY9CQDvaW-P2MSQhaGvP-yVYBFHqNvOH_XgaBVdW5c35AuLGz3pVAiBl9s_Ghrkc5h0KrhU_eko5YAMGcXHUQPask-EVy4MYes_3ube_PbQLTvTgVZ6XwMjPNIOkYvrGsZrRZbRCDXKqc0KBFi2YT_dQWaoiNgg ca.crt: 1025 bytes Name: cronjob-controller-token-6hfqf Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: cronjob-controller kubernetes.io/service-account.uid: 0e4b090e-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJjcm9uam9iLWNvbnRyb2xsZXItdG9rZW4tNmhmcWYiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiY3JvbmpvYi1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMGU0YjA5MGUtZTlkNC0xMWViLWIyNWItMDI0MmFjMTEwMDA5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmNyb25qb2ItY29udHJvbGxlciJ9.SKICsFaSIGnrn9pfqWg_Vrw1jBvYz_bc95tJ53FL_M9b6YQKgHRQZZH1DQciGdSd27nYSWnoG9L-ftKEZhaU7ABAAga3lNzyDJhgPdYtCy8OlxzY2nY2RdDbCsFRjaK76aIJQf_u0z8K-JSz6CjELBj294WWbXoAreCtZiQGRrrupgtUIPjUloaqx07BO2Y29N2ZMkELj_Ye5rSeffnz_djSFdwTIt6B3Jtxjp55DZjMzaj_coqmVXfGq4K90wkKlWLIbbAGYlRqEfJCpIK2OeCy5WF2EahlAUECHEQi5NqEQ1DoiVUj1LtdwQOGKXlQYT6h6GSLY_E1Q1Xv3vWFjQ Name: daemon-set-controller-token-6ftrt Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: daemon-set-controller kubernetes.io/service-account.uid: 0e251630-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYWVtb24tc2V0LWNvbnRyb2xsZXItdG9rZW4tNmZ0cnQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFlbW9uLXNldC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMGUyNTE2MzAtZTlkNC0xMWViLWIyNWItMDI0MmFjMTEwMDA5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhZW1vbi1zZXQtY29udHJvbGxlciJ9.OTdB75fb-wdKbbcZJ3mS08JuJsq3urdovVUgiADbpAZnL4pVZWdAmrLadYVKFNqfXOlCaSqQefLNgSWsGcJee-YSQT6snP87Wplfo7VH05h9Xwnoz21uWpkjhIlioWbcKL1asBuBsvpSczqg4Bt3cyByxdrIJjBmBvoJpFhwf04IqyJ6ugxDLPTH-8CC5r5Xn6etm8Ey-p1rwQJb1u2FEq8K97nihv87TByrHLQv-CMn1wxfGHDYOEAneis2s0pWotvxrHWkFg1WnriDAq4hryGPDA9GRLqveFdCL76XTuT9plYFYMxLRF-8_EuwOwTa0F-LYm98o3iDhbvwkTDhiA ca.crt: 1025 bytes Name: default-token-jw2ql Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: default kubernetes.io/service-account.uid: 0fdb30ea-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZWZhdWx0LXRva2VuLWp3MnFsIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImRlZmF1bHQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwZmRiMzBlYS1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06ZGVmYXVsdCJ9.ijnMq7u2xRTNKXov89YF67O27Jn7uLqnRYzK4V95pWt22dN3Qayf7U-jlLm6uWec79FLKNM_08IjnobzVxnzrFhRqLqOT55mkyLfXdNdR9EE__CrPOs-PiSIsHNbAG64bUSDOwbGaFjKROFBz1dwHj1O_XQZfLNaH3_LhLzOHtxJ4_FyOOf-hhjEWgjOptptTMkU3N_z7TRU4zzX9BUWTDg5s6JBpFkDSbZ-_yu-uzl4JiEBUwf0MY3YC79caRp9uFgwuaMCoFJYV7gSqWA5IpqgQe225LBTBS2HHLPJE67WLlSrkiEe4gvngnGtO_1RkO2MBCXgVp5icSFw4zxEzw Name: deployment-controller-token-fctz8 Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: deployment-controller kubernetes.io/service-account.uid: 0cd7cffc-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZXBsb3ltZW50LWNvbnRyb2xsZXItdG9rZW4tZmN0ejgiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVwbG95bWVudC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMGNkN2NmZmMtZTlkNC0xMWViLWIyNWItMDI0MmFjMTEwMDA5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRlcGxveW1lbnQtY29udHJvbGxlciJ9.uobekKRLj02hr-qsNZCPNZWER2mYiZj8NCygiXz5c_r9B7AjhHkq3MlcfPe1RoU89P3hofrNWQpTY1Kikl9nspKQ_Yve2ykZidGGGoOtuaqI2h-SfNMjeqHGXM0CmQAEigrmkQtDrkwt-lz3pXEacRbh5pmS8BOWvpgfc5e8qt39YebFTKygNvCYvMgYMy5MsufSDeifFcb7J12hhXczxvYLDcbgDewhEnpxA887KaQlCML8soNmM36bC5qEU3nrGnKg1a5kvjjxaxres7VRb4U9fs0xogLAzcAsuOd40Re7QY8wNdY7dcUg2qivFSm7P-3vbiZ9Twr1kftazuR6Gg Name: disruption-controller-token-x8n2f Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: disruption-controller kubernetes.io/service-account.uid: 0cf3a17c-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkaXNydXB0aW9uLWNvbnRyb2xsZXItdG9rZW4teDhuMmYiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGlzcnVwdGlvbi1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMGNmM2ExN2MtZTlkNC0xMWViLWIyNWItMDI0MmFjMTEwMDA5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRpc3J1cHRpb24tY29udHJvbGxlciJ9.mu_3XUNoOGZwHlTyhKygDwAFjIWY0Uf0foIiS4vGNsnBBe5AUz3bN7gD0f7EpRZoI7KeIL-OWYGLvjtsCgC-1lYCRm9DNLmNxYnoDiNcbpCFx-xHF4E4yl4v51oJtXG1Bc-Xva-S15US673Gzv-soVAfpVKOzYQVklM1cbim__Eb_vXEZ_i0r-KD1DRNERMZWjvJ159DuiKMjd6CCzkgXCSQV1K4jS2jd2taiARKUcGNw0rQBeHh1_IN460jnMGCLM0lzbcZZAA4YKhdMfsU2AjIlsvK4k6VS5G-w4lo3PA1JW4Ve-Z-Im94Lqd67A2MSqUhWLPw1cn4PGGyWTaiJA ca.crt: 1025 bytes Name: endpoint-controller-token-qbz7h Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: endpoint-controller kubernetes.io/service-account.uid: 0ab80371-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJlbmRwb2ludC1jb250cm9sbGVyLXRva2VuLXFiejdoIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImVuZHBvaW50LWNvbnRyb2xsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwYWI4MDM3MS1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06ZW5kcG9pbnQtY29udHJvbGxlciJ9.z4jN9B3eHKiw7RTSz-UM0RqGiPXX2-7bV9d6N-6hkfPDCfOj3BwjApxqc3FoDiPeazVSNT-cmORpgAP3b5UMYYnN5wNw2R4XfysUXfY46i1clQJqZ14o9olfX1KegC1T-yZOC8MoEHMFvngem5gEfQquW6cIM6hYQ-kgWHaYRZwH00OqPg9YchBpmmm7erx5PZXmlWmZ76lobAyi-nAzShqJA5mKl0amSwzfQfd7ErZJhsHJrWynqpJi_SSTRsDL2zYY79aiNEMaXe4nXa0rlyVNZmRRiaA3_ca665S840KTMjvLfub4fShxpRib8EEnRJOAJft6kyfCn6bf2Uf1Og Name: expand-controller-token-q7k8m Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: expand-controller kubernetes.io/service-account.uid: 0fc0ecea-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJleHBhbmQtY29udHJvbGxlci10b2tlbi1xN2s4bSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJleHBhbmQtY29udHJvbGxlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBmYzBlY2VhLWU5ZDQtMTFlYi1iMjViLTAyNDJhYzExMDAwOSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTpleHBhbmQtY29udHJvbGxlciJ9.w0CjgPX7fKK1huV-Lt0ZRGLo5JgMiAR9yn11R0CrsIyDyPGRlwOrUoDSRxNn0t__Bq6YSjblPDAjz0hh2PToc44g4abe1aSfF2cXtps1y87Jee78jQ3rF9vGzinqPCJGmiXCZNvAunEAT88KkiaND74X3rHgPU-E0XjlNVyjlwMRUQWpA4Z7rqMTSb448L9vjFETbT4n7jdFib3iijeP8MgcKDxiZYpkKhQcsvvO-r-r6ndHRw7_eO06Yyl-nW20NALbc3CB8gl-1JLuFkB0CsVE2J8D3s8vkQ1rd0fMPo67cgqnc5jCULRgKWYoKOaGtcCc_UdxOg_P_9gS3zfhjA ca.crt: 1025 bytes Name: generic-garbage-collector-token-qkjc7 Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: generic-garbage-collector kubernetes.io/service-account.uid: 0f46f27b-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJnZW5lcmljLWdhcmJhZ2UtY29sbGVjdG9yLXRva2VuLXFramM3Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImdlbmVyaWMtZ2FyYmFnZS1jb2xsZWN0b3IiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwZjQ2ZjI3Yi1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06Z2VuZXJpYy1nYXJiYWdlLWNvbGxlY3RvciJ9.cVdg68sCtTFnHtZenBGyzJx5RRxPekXORa8L4et-5F5WVoAyvVLIc4g1kPEWgdrGQwAbXsgjowYEGZiZZM7VjHLTKpiHaYuYyFjPVtK-bBc4EuB4bPhX-5h0w5A5e1npDTqRHohIel9Q4Tx9bCfMGtzoP9C33Dog5kIFbNA1h45YaT5DUSIe9lnD8MbDbf6JoLLitB-jJdv9B7oscm7b-azrZpoU6ffe6KifzkZmlfbjwuQJtXDzgL4fD0wzTCfNP1Iun69u5NdejbEhWA2lS0Gt4KNgMX3wSQgL_4_htOs2__PwlH3d1F-VmZFweVJD6CSBqpttsgBEO3y1dwkM8w ca.crt: 1025 bytes namespace: 11 bytes Name: horizontal-pod-autoscaler-token-v46ss Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: horizontal-pod-autoscaler kubernetes.io/service-account.uid: 0d30b7d4-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJob3Jpem9udGFsLXBvZC1hdXRvc2NhbGVyLXRva2VuLXY0NnNzIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6Imhvcml6b250YWwtcG9kLWF1dG9zY2FsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwZDMwYjdkNC1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06aG9yaXpvbnRhbC1wb2QtYXV0b3NjYWxlciJ9.0nwfw8R2M_qtziNugziYCoGFn-aXOHUrCWea6akqBGXBaIXVW0OCeLip3oW2WO2Il4LMHAFL_xSeqCkrIXgCO_LYGGbnQ0yS_QfLsDTDUzPOZzx4_o9COOWF-rfz_7OK8T01k5xns5_Gjxhh7sWpXv5IrrGeFhIWAS10d-CPXAOx-pt2r0aG4Vg-Pn3bPVi7DZvgED5LURx-kFSTsRRN8HX32jNmLKCcQ_mn3MRrBeOohf2tvCISqVzkMZfSN-fHiemZLXqQQlD25fC1zkLLQzDHoQn_A1VKH53Ac12xso0Z1r1tK4F38L85QLhV7QE-471kYjgJMJsSWv3SbcmnRg Name: job-controller-token-cmwfj Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: job-controller kubernetes.io/service-account.uid: 0ac95588-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJqb2ItY29udHJvbGxlci10b2tlbi1jbXdmaiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJqb2ItY29udHJvbGxlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBhYzk1NTg4LWU5ZDQtMTFlYi1iMjViLTAyNDJhYzExMDAwOSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTpqb2ItY29udHJvbGxlciJ9.JFVVRYktyZFtJTwkepgJ5xFLJZXJReBN11ebo242b7LmembqxN3dw6qaNqd9gKJpaekzcUSJaCQDlHBivbW637YSfBsR2zov3US1_lVfm1jRCJ9Li8787-V8YcQmUCyM-gxbqwER15Sx3fGYhQicgDDVLuQ1JDfz3-9RTScKKTHOoFdpU0cmfB4kfgi4OaSl5hRvW33mi4psxLem-TjXV6EmYgGvfduVm6TGoewT-3uU2K7b9_rMLDLz6B85uolAJ_V0wajv8ZZjerTon3NyLFo5Uta_zt-gauEzaxGTVk4GHYIMhQ6-PTPZ2KpQVN8MI3j7kF9KJ9-nZ5gsvyEI4A ca.crt: 1025 bytes Name: kube-proxy-token-ssgzc Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: kube-proxy kubernetes.io/service-account.uid: 0cea9f15-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlLXByb3h5LXRva2VuLXNzZ3pjIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6Imt1YmUtcHJveHkiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwY2VhOWYxNS1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06a3ViZS1wcm94eSJ9.IzyixUsktQs4oQAQ-r1PTbtRrBrVf7elWCypxBkUHDhBjNQOZIjt0VnIjRoTdJenIOCH6tAmeMddJMWs8nYRMte_Pi-_XylesQypzAeiuE4oT8bxGZAC2H6JJV1D2OIrYaABWJzVejqakkrtsk5RQBbMMyXlkFK1_R1YP-5XmhzyNyfCaKzi9cprbQNX3IV72I9R9DUo6YwO3j0r_5cnKMfgPAk95ACrwqglYMpLWCFFRDjS7vWSW_ue65Yohvs85xBvYiG_ybkN75eegQYt-1AS6T0S-TBY2V3lyfO4k52VomAm34d1WgPjUyWUEun5ywH9ucDU7T_tGH4rzf66Kw Name: kubernetes-dashboard-certs Namespace: kube-system Labels: k8s-app=kubernetes-dashboard Annotations: Type: Opaque Data ==== Name: kubernetes-dashboard-key-holder Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Type: Opaque Data ==== priv: 1679 bytes pub: 459 bytes Name: kubernetes-dashboard-token-njndv Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: kubernetes-dashboard kubernetes.io/service-account.uid: 41afcd0e-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC10b2tlbi1uam5kdiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjQxYWZjZDBlLWU5ZDQtMTFlYi1iMjViLTAyNDJhYzExMDAwOSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJlcm5ldGVzLWRhc2hib2FyZCJ9.LirJ7cHBUyF30S6KKjKMNI27WLL2MC2gPPhJc1GovzWgTwUWVPYImNcXYoUOVUZ-ZJwqT9ukOH_0vxF2kblKW3xSmB_rHQ3cvs6daVNA5-HPeBT8kq0EhiRlFALYezgKpCgkpiXvTE6MGNjMhHPJ0C8yi8jEY6OC9Y4DZQXmPQV3B2Xpk7ZoaMXoHFHfPTDSpNdeWSUJN9JErrmVBFpWeTuGI6m9A2wInQY1zjLiCm-iH9y0AbpwYg1QKGWNvKVSwYkS4ViDA6qKEzGWQxWSbCdsCIGhjGNz_nxMoVm1yPeU4W1yn-Psk6LLiIzSpizZTl-3VfIR0dl5mNHq7N3KPg Name: namespace-controller-token-smw7m Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: namespace-controller kubernetes.io/service-account.uid: 0f20a4d0-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJuYW1lc3BhY2UtY29udHJvbGxlci10b2tlbi1zbXc3bSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJuYW1lc3BhY2UtY29udHJvbGxlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBmMjBhNGQwLWU5ZDQtMTFlYi1iMjViLTAyNDJhYzExMDAwOSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTpuYW1lc3BhY2UtY29udHJvbGxlciJ9.pQGalvSM_lh41fNKsY2ddZghUe_lJuz9Y9rmbXY0V-RjmF0BagSobz9SxucHAAOttIraamgTKksbxLEoAV509Yfxf62ybE4cW9KPggozc8iluwGLkdWYdGZxVe4midlnYcIpYTv4Zueav8f-9W2cGWyzHustTZf3R9b2A5N02uT91aZ38QWllsy_WKMVAaDLCLel71koJ_HjjDqrZ_ObO-YAtBeA9zslY0nhH-mpj0WsjW76Af4pVTotFBGdqtO9eV3Oe_H6sy6y2BAjxItGDTU9xvq7f3-taa-SB9j5XbEPJ1I8ObxcOLhYtvyCcHf2ZbxR9vVJ1CLR4ymry1mD2w Name: node-controller-token-9ppdt Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: node-controller kubernetes.io/service-account.uid: 0d0b0ff7-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJub2RlLWNvbnRyb2xsZXItdG9rZW4tOXBwZHQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoibm9kZS1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMGQwYjBmZjctZTlkNC0xMWViLWIyNWItMDI0MmFjMTEwMDA5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOm5vZGUtY29udHJvbGxlciJ9.Hg-v6PYzmoSmC-FVhE07OVOtLSGb7eIDPeY77k9l4tlCT8wDPNSo3zF8LKlsKCehDeKVfQL6bdcG596ECF_Vh0zHjswZrZMCsOWO0sBArDLzOu6Zo2wgvbkPZHYA0X7nt5jc10W_q-Nw1Ud3WLNtW7v4iWpbeGZGz7EgCrqW5XqYxA9P8CA4jdMBmdit-zwjaJUu5jjIYRbeYQhKF8hrC00vMXyYMRZp2dzGSMAmI4yF2OO-QdKc1Mieq-w4i8pOl7gO4nYRLQCAcdY2TjCO5VbcigZ6IWzzQb120WgC2Iqd5mhSzcmMFcrT1IbzOm91bFkgwGAs1oQw8Cy8iCV9SQ Name: persistent-volume-binder-token-9hjlk Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: persistent-volume-binder kubernetes.io/service-account.uid: 0fb0da85-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJwZXJzaXN0ZW50LXZvbHVtZS1iaW5kZXItdG9rZW4tOWhqbGsiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicGVyc2lzdGVudC12b2x1bWUtYmluZGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMGZiMGRhODUtZTlkNC0xMWViLWIyNWItMDI0MmFjMTEwMDA5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnBlcnNpc3RlbnQtdm9sdW1lLWJpbmRlciJ9.MbBQ48J2l7rgogx8YWgbX5ys_oyNBLBOn0xsuhO5_8jIKLwV5hup5X2JdjwTCw0uGZ0lkYgYANXnnK2Q39mlsJLMYCudaVWGZm7IumjyLuu9CkvhUmEHhYmqY2if-PAAXxaO_hKSbEpsmBEQKWGnU69wUdsEoQdBwqlHg4jZ69dXvrMsBgJ96ic_511e9B8R_GPKS1IXocTJtFcbCp-rpbk9REBGYQB-Fjh2UBpPvmeFQcfZ39yvBRMmi1LWW7sTQtwEiTErgYcIPpr7klSguSApm9un75P4tCjLPNFbIjUbf3lCqonwtEwADD1sKg2f9TSxdverIhoXX90IBJBTUA Name: pod-garbage-collector-token-l42r5 Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: pod-garbage-collector kubernetes.io/service-account.uid: 0dfebd7d-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJwb2QtZ2FyYmFnZS1jb2xsZWN0b3ItdG9rZW4tbDQycjUiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicG9kLWdhcmJhZ2UtY29sbGVjdG9yIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMGRmZWJkN2QtZTlkNC0xMWViLWIyNWItMDI0MmFjMTEwMDA5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnBvZC1nYXJiYWdlLWNvbGxlY3RvciJ9.VaMklkb7hlu7MRkn0rE2Tlu-lJoeXQI4aB7qVGGHisp3nGVOjSodrldgQUxFnO3oJ9invV6RcYIS-yCaBfL8c0tak7yrGSWI2gjIrM-nS16PgLDYPjbZqJk9wXKIdzqt63Nt8HvQfBdi0IKmyM8eszOXywpHX9wyJFBGH5PYRdBs3HbpzNg5_GdjPO2IGbQGwZyyonb0o1_xk4GH-bAfbe3fCsHN5N1zY39DNo-qJ6xWC89Xfufgw95-_JxR_Pd7IiuUyqFN9KxqrbvdqdtML2ZS53fvpNqZ62_a9nK6xefGIgfxBXov_eqsjlBKh7R0vXyFAHpn3yTLUKZP-zHtGg Name: pv-protection-controller-token-qp2xr Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: pv-protection-controller kubernetes.io/service-account.uid: 0ed4594d-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJwdi1wcm90ZWN0aW9uLWNvbnRyb2xsZXItdG9rZW4tcXAyeHIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicHYtcHJvdGVjdGlvbi1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMGVkNDU5NGQtZTlkNC0xMWViLWIyNWItMDI0MmFjMTEwMDA5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnB2LXByb3RlY3Rpb24tY29udHJvbGxlciJ9.e52Sqc6aGtwNO4ecQRqddvzWsqkVOvj0MtMT8DmLf21sxv3W0yDDJYYTz6rzljqJPOkP7JBoNVoZL80e0NCXArmA27B4vCPTzCnSCrSSquoljMvxFmalnnJke6TQZKhplDtMy16orAM00Dr4KAUcphDP0uwO2Lsu6uSyFxiMQ53nRxzRt8fIf2HJZecHnvxA3qYKDpJ9ceZK0EgtzSBCSY8qNW9hVvAlUUjCkoJHeSzBeIrJTrI9GzYkkeqWfIdLy9fBpYHiCSxScKg7IVQ7iPqyZjYoo9BFKeXiIS87fD9qCh_xOAIKtmjAWmgaabEqcUx-kefbVTNKLhWn1AUyGw Name: pvc-protection-controller-token-b6q9s Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: pvc-protection-controller kubernetes.io/service-account.uid: 0ad1b174-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJwdmMtcHJvdGVjdGlvbi1jb250cm9sbGVyLXRva2VuLWI2cTlzIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6InB2Yy1wcm90ZWN0aW9uLWNvbnRyb2xsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwYWQxYjE3NC1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06cHZjLXByb3RlY3Rpb24tY29udHJvbGxlciJ9.TeJQ1uCU_Jx5c7L6eZ2Is20BT9SmwvadmZdK7fF4W0jGzlohLbS-ACQQJTMszWxti9BiAxke_bijrUoKZElDlbNpgXqiqnxaIAUdJIkVPm8IQpVN7d0GfYmEeHcUl5kUHO5Oc9AFqFcQeknxcTo8RI839SXp595DHTq0SPT3gaMfSqpV3dHIlSHixBke9oG9bTYo4OoAOljfq2OT30JQSk_Z-6-_ftvCxyVtgGZGs9jyC462ic5oxQ8U4BwJoPxmTCXn_aQPXygmlONMsAo4HIRzCmv2eey44oKvGBR5cInhGaoP-SUWuc0JG1PZFDLIllU2lod-DBSdxm7err6cTQ Name: replicaset-controller-token-9mx8t Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: replicaset-controller kubernetes.io/service-account.uid: 0cf1ad30-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJyZXBsaWNhc2V0LWNvbnRyb2xsZXItdG9rZW4tOW14OHQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicmVwbGljYXNldC1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMGNmMWFkMzAtZTlkNC0xMWViLWIyNWItMDI0MmFjMTEwMDA5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnJlcGxpY2FzZXQtY29udHJvbGxlciJ9.c5PbPe1CGfhMX1LzxQcQKPm3bNIFjwf9HXtSHs-wzF3caLtwNqiqczQid6F2Nf2EWbgG-ZarSJ1ESMdoPEvNprF-prVNXxeoTAuX4C9re-0zcCuZTGpxRvLq_IPZRJUHj12d3Lr8JAXdgJFBRvwQZhgDe0Tyinh5JJnNwlWvZ07mMBOVbAgcq2Ut_oAwu9DCiNv-gZHqBI-BISH6a7uF6YIdBOKIJxkTs3D3aaPYtyw-a0qBp2bAlRa3Un0IgjDUe9eiCGAc1cYRYuWUV-Ro2zrOBxwvVCh6r7iIWIuHb7y8Lc9NkbTXnxOSLwOyaCCkuioiSa_LytFlhCJlC09ubA Name: replication-controller-token-99sjd Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: replication-controller kubernetes.io/service-account.uid: 0efa8a2d-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJyZXBsaWNhdGlvbi1jb250cm9sbGVyLXRva2VuLTk5c2pkIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6InJlcGxpY2F0aW9uLWNvbnRyb2xsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwZWZhOGEyZC1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06cmVwbGljYXRpb24tY29udHJvbGxlciJ9.d157wtS1_qaJdrOFJsmZR37qe7XwvIypzUOJHU4UZpvynL2Na2Wim1xH9-n5AlS-fO_VdwrkBSG7Ef8XV_sziJ9jJmLU2vXo_ZH6CVohviJyxkAob465QCVjjuvKwCgxS7vYCpJ78Y5Vdr7PDFu28X_kd3tNAIuhPMlhj5aeL5NWUmsRSo5aXl4DhoossqF81GkcmKe-kuMSnm9BOFNxokTDA2zFWbOtT6oK7ZSz2oKVN8YoIu5534nmH7-ydokDrcNgUnqy9ByTA8BAZp7ueMlIc5xktJlvt6sQ8a3gNg90j_3H2RCA1wQZJcIaB8IVVXe2bt0ZaQI9wrYBBb7vEg Name: resourcequota-controller-token-hdch8 Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: resourcequota-controller kubernetes.io/service-account.uid: 0e881d99-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJyZXNvdXJjZXF1b3RhLWNvbnRyb2xsZXItdG9rZW4taGRjaDgiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoicmVzb3VyY2VxdW90YS1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMGU4ODFkOTktZTlkNC0xMWViLWIyNWItMDI0MmFjMTEwMDA5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnJlc291cmNlcXVvdGEtY29udHJvbGxlciJ9.omLEn20jTg0sn6P8Gihen5l3IuxFNIxK79wv_q00aOsGsAK1BbFQlIOWKHqaO81yvS3T_7UXSyCr01HTVhXabsJPS82t1Gr7jzzN4AKM230nHW_VGRjgU2gN4GxgAYByOTXBootTINz37J9Kmz0HSdTkIuqylXR6pUVrLKYJU2YqPqWe1fcoOi8P66d5qmpXfj806hw2SJgvxrf36v9cGMeoK5JDa1rI7VFAVLR-kWy9LgLQpVzDfuNqHAznay1wBcT3_Kb6l4JOkd_QdNZRl0xsP1NZMVaPqrbsxxO5us3_idNtZvo9fSsQU9itxodtnqBeSSlnvZH1Kr4tVa-7eg Name: service-account-controller-token-n268k Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: service-account-controller kubernetes.io/service-account.uid: 0ad49e7f-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJzZXJ2aWNlLWFjY291bnQtY29udHJvbGxlci10b2tlbi1uMjY4ayIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJzZXJ2aWNlLWFjY291bnQtY29udHJvbGxlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBhZDQ5ZTdmLWU5ZDQtMTFlYi1iMjViLTAyNDJhYzExMDAwOSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTpzZXJ2aWNlLWFjY291bnQtY29udHJvbGxlciJ9.gVr-OJa0nVuUTFjsUwdAeiQQHEFVztiXUQfV7AgRmi850C1QiwpiBAejT8wOK6lwhOrhzT5EQ77ITqmTQZz1BC_PfZRgdNdZz6Ytw01TW4AeWe3A723yiqFDnasmFB7XhbKDQxFLd0dw5VjlDsdaEu0IIU0rdQKul8EUiccJolP2s-5V4FvvPfcPqnuFTlbbTiv509DE9G1ZTcZ4TxcBx4-0aiIe_vdUjuE2ECaOIPry0rN1yg3JNA5mJhOM6hAfmaz-DzH7DNh134RiWdHxQxQqeoRrlby2aS7IayT_JSiSZecoYGvL-CFteJdzMEWqWzIzMuDb9uzHJ1CBzOezbQ Name: service-controller-token-dgqch Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: service-controller kubernetes.io/service-account.uid: 0ce95734-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJzZXJ2aWNlLWNvbnRyb2xsZXItdG9rZW4tZGdxY2giLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoic2VydmljZS1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMGNlOTU3MzQtZTlkNC0xMWViLWIyNWItMDI0MmFjMTEwMDA5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOnNlcnZpY2UtY29udHJvbGxlciJ9.b7Y5beL-iAl64nYe_gTiD8ogwl5GTLpeE9GBxaEMKy3KbLiags3p-0ZqXLoDD_e91BaPxpmUyRfavWV5lZ85uzzBdH-q4aD6FnwHBmoTwbw3TK1znxCeri9xObQNmxDPH7CjVQLVHbksMFGum1L1xWCf3dw0p2ZrPbgzRzq93uUYjiW-w2H40Ub0q9TFTp9ic-T6wRq4DqT8XgBKa__nNblCHiM8hlZ6ufHFYeE4aAFcLLc1RaKvFxH7oO10AJ0fB45NwaMPa1iC0O5dTl57jQbh9mxusLtKAysAMMugObnCJ9yYSA65n9p9OsYTYZVp0OOCRGu7P4lO3XR3ZLr1-Q Name: statefulset-controller-token-j7858 Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: statefulset-controller kubernetes.io/service-account.uid: 0ce28a94-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJzdGF0ZWZ1bHNldC1jb250cm9sbGVyLXRva2VuLWo3ODU4Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6InN0YXRlZnVsc2V0LWNvbnRyb2xsZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwY2UyOGE5NC1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06c3RhdGVmdWxzZXQtY29udHJvbGxlciJ9.ju-pOwheRoeE61w_NiQ8jLXFFhIb0SA6uaOFcKR5SmaN4bhQYIdlK0IywWQwu6RzCzIgCr4XrGrWsxblNpBMQC2-dNIuELWIMAFR5gjKQZh4v2Zmh4ysXGhbj7repAOLYvcseN-tGW3hax4IywN0GI5Pw257xoHPXZToA9lnqnIPiVdzlSOe8WBfhv6omdeGmtrgNGkgAjh2LiXViwPW7V3DVPjIY5d3k0v3pqzHSuxNYTRdjqcg53TMNTUFe2LKTVbzmgLngdKufOPmtabtnxU21r1ua887BCxl9RO7FUm01CTBlofKF5wkaGr5_w6zXRVgLE6Fo4YrhILf1z1BaQ Name: token-cleaner-token-9fvhw Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: token-cleaner kubernetes.io/service-account.uid: 0eb7ce45-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJ0b2tlbi1jbGVhbmVyLXRva2VuLTlmdmh3Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6InRva2VuLWNsZWFuZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwZWI3Y2U0NS1lOWQ0LTExZWItYjI1Yi0wMjQyYWMxMTAwMDkiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06dG9rZW4tY2xlYW5lciJ9.QDNslXVqy5OPVb2mKpgsBDpWbTIaSgaZtjnvwwlsxyARYyLDuBHHpik2_IcmVI94riv3LF-WKI2m3fw9uAlkQRmebQCNCDYKWiJEttvEXIgb6vcwEIO3Bp2Q-nbwPjzxvGHmxluidzKZ4EIusyxqsxoMCPevMmsYHQWhegIvezE8tL_7oUPIx_rGW1lqB6ohZwjSPHTXvnmzqvP1zQDmwPMDN4Neqy3W-ahOAmBdlGx1cnPtEWY7z4cN7oMqY_l4CXwbZbq54Dh6M9ODZmiwd5TarLGv2fqaNpiG5YZwtlnRz9cAIC8GfGz_OAsj9bMLkt3yC_SHHdXeQ3UYQijYkA Name: ttl-controller-token-wpd5f Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: ttl-controller kubernetes.io/service-account.uid: 0d9b87be-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJ0dGwtY29udHJvbGxlci10b2tlbi13cGQ1ZiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJ0dGwtY29udHJvbGxlciIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjBkOWI4N2JlLWU5ZDQtMTFlYi1iMjViLTAyNDJhYzExMDAwOSIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTp0dGwtY29udHJvbGxlciJ9.jSUdoCKEBQYkAL5GtVQWCzFmH4FQ6GaenbDm9Cu5psOGhAd7_fpPejjmTinedpCmv0KgYIfOpzWyjQ-b1lJciZ9OFBapVDh--51kYR-enbhXpa5EP8T5O0PcnzXRojRZPMGPgQBWbn4JgTrfplzLRlrjFInTJVXA08a6B5rYXXmdABMCD08eaba9M4XeFuCIYoStmNhYw-fBPbtBegTif2ToT47-EojkMJnL8qI-oOL1nAbFHwaHSPC-czpf7VgSRBpnfTzbGrtrRwUX3vbYrrSTGo2RK87P9Qqb7HPWLnM1LDKHlgwkNmUpp9Dt8Tmun8XYWOpfQwaAqn6zRpbsPA Name: weave-net-token-fn28h Namespace: kube-system Labels: \u0026lt;none\u0026gt; Annotations: kubernetes.io/service-account.name: weave-net kubernetes.io/service-account.uid: 0d455a77-e9d4-11eb-b25b-0242ac110009 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1025 bytes namespace: 11 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJ3ZWF2ZS1uZXQtdG9rZW4tZm4yOGgiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoid2VhdmUtbmV0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMGQ0NTVhNzctZTlkNC0xMWViLWIyNWItMDI0MmFjMTEwMDA5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOndlYXZlLW5ldCJ9.PpqFn31z-GiFAdE-Nd9-R8xuW8ESiisX53Vn_niAvFQ2DPII8q4150iNJDedLZ6nZiXBgV4e7b3NcZzNGhwRVAUyRgLrIqjdgNk-04YJ40bdP4d_5hSUylEn_QH1dgON6tMV9cK6skC0weFZzpPptGhA0bhyFdNl3DvGKGGmMgfyQsf3tEjZjEyqOuPLPtW0TPF2h98UmSsBzWbn-tCM_GEZTVY-3uxzfn2AfkuSI-e9ri1W4X8_W1z_cFIXk4Pwg0q7RWcJi44BCBJE079ezRLIWbowjXOXpqrZwe_jw_F-fJI_7ddxWDx68-wBwhjVIdNqnnMvzB-RKfgaIcWEiw 部署仪表板时，它使用 externalIPs 将服务绑定到端口 8443。这使得仪表板可供集群外部使用，并可在 https://2886795309-8443-elsy05.environments.katacoda.com/ 中查看\n使用 admin-user 令牌访问仪表板。\n对于生产环境，建议使用 kubectl proxy 来访问仪表板，而不是 externalIP。在 https://github.com/kubernetes/dashboard 上查看更多详细信息。\n","date":"2021-07-20T11:05:00+08:00","image":"https://www.catfish.top/p/k8s-basic-2/kubernates_hu999cd8b4a0602898549f5ade1550b92a_32166_120x120_fill_box_smart1_2.png","permalink":"https://www.catfish.top/p/k8s-basic-2/","title":"Kubernetes初探（二）"},{"content":" Katacoda在线课：https://www.katacoda.com/courses/kubernetes/launch-single-node-cluster\n本系列教程希望能通过交互式学习网站与传统方式结合，更高效、容易的学习知识。 本系列教程将使用 Katacoda在线学习平台 完成学习。\n Minikube 是一个可以轻松在本地运行 Kubernetes 的工具。 Minikube 是一个在本地上计算机的虚拟机内运行一个单节点 Kubernetes 集群，便于用户能够完成日常开发工作，同时也能够让新用户快速了解Kubernetes。\n详情见： https://github.com/kubernetes/minikube\n步骤 1 - 启动Minikube Minikube已经安装并配置到环境中。通过运行 minikube version 命令检查它是否已正确安装。\n$ minikube version minikube version: v1.8.1 commit: cbda04cf6bbe65e987ae52bb393c10099ab62014 通过运行 minikube start 命令启动集群。\n$ minikube start --wait=false * minikube v1.8.1 on Ubuntu 18.04 * Using the none driver based on user configuration * Running on localhost (CPUs=2, Memory=2460MB, Disk=145651MB) ... * OS release is Ubuntu 18.04.4 LTS * Preparing Kubernetes v1.17.3 on Docker 19.03.6 ... - kubelet.resolv-conf=/run/systemd/resolve/resolv.conf * Launching Kubernetes ... * Enabling addons: default-storageclass, storage-provisioner * Configuring local host environment ... * Done! kubectl is now configured to use \u0026#34;minikube\u0026#34; 现在，您的在线终端中有一个正在运行的 Kubernetes 集群。 Minikube会启动一个虚拟机为K8S集群提供运行环境。\n步骤 2 - 集群信息 用户使用 kubectl 客户端与集群交互。该工具用于管理 Kubernetes 和在集群上运行的应用程序.\n通过kubectl cluster-info命令查看集群详情信息和健康状态。\n$ kubectl cluster-info Kubernetes master is running at https://172.17.0.10:8443 KubeDNS is running at https://172.17.0.10:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use \u0026#39;kubectl cluster-info dump\u0026#39;. 通过kubectl get nodes查看集群中的各节点信息。\n$ kubectl get nodes NAME STATUS ROLES AGE VERSION minikube Ready master 9m15s v1.17.3 如果节点被标记为 NotReady 则它仍在启动组件阶段。\n此命令显示可用于托管我们的应用程序的所有节点。现在我们只有一个节点，可以看到它的状态是Ready。\n步骤 3 - 部署容器 现在可以通过 Kubernetes 集群来部署容器。\nkubectl run命令能够将容器部署到集群中。\n$ kubectl create deployment first-deployment --image=katacoda/docker-http-server deployment.apps/first-deployment created 部署状态可以通过Pods的运行状态得知。\n$ kubectl get pods NAME READY STATUS RESTARTS AGE first-deployment-666c48b44-n7qjz 1/1 Running 0 60s 容器运行后，可以根据需求使用不同的网络选项公开暴露接口。其中的一种解决方案是 NodePort，它为容器提供动态端口。\n$ kubectl expose deployment first-deployment --port=80 --type=NodePort service/first-deployment exposed 下面的命令能够查询到绑定的端口，并且能够发送HTTP请求进行测试。\n$ export PORT=$(kubectl get svc first-deployment -o go-template=\u0026#39;{{range.spec.ports}}{{if .nodePort}}{{.nodePort}}{{\u0026#34;\\n\u0026#34;}}{{end}}{{end}}\u0026#39;) $ echo \u0026#34;Accessing host01:$PORT\u0026#34; Accessing host01:32492 $ curl host01:$PORT \u0026lt;h1\u0026gt;This request was processed by host: first-deployment-666c48b44-n7qjz\u0026lt;/h1\u0026gt; 结果显示的是处理请求的容器。\n步骤 4 - 仪表盘 使用 Minikube命令启用仪表板\n$ minikube addons enable dashboard * The \u0026#39;dashboard\u0026#39; addon is enabled 通过使用yaml文件来定义部署Kubernetes Dashboard。该配置仅适用于Katacoda\n/opt/kubernetes-dashboard.yaml\napiVersion:v1kind:Namespacemetadata:labels:addonmanager.kubernetes.io/mode:Reconcilekubernetes.io/minikube-addons:dashboardname:kubernetes-dashboardselfLink:/api/v1/namespaces/kubernetes-dashboardspec:finalizers:- kubernetesstatus:phase:Active---apiVersion:v1kind:Servicemetadata:labels:app:kubernetes-dashboardname:kubernetes-dashboard-katacodanamespace:kubernetes-dashboardspec:ports:- port:80protocol:TCPtargetPort:9090nodePort:30000selector:k8s-app:kubernetes-dashboardtype:NodePort$ kubectl apply -f /opt/kubernetes-dashboard.yaml namespace/kubernetes-dashboard configured service/kubernetes-dashboard-katacoda created 可以使用Kubernetes仪表板查看部署到集群中的应用程序。仪表板将部署在 30000 端口，但需要一段时间才能完成启动。\n要查看 Dashboard启动的进度，请使用 kubectl get pods -n kubernetes-dashboard -w 查看 kube-system命名空间中的 Pod\n$ kubectl get pods -n kubernetes-dashboard -w NAME READY STATUS RESTARTS AGE dashboard-metrics-scraper-7b64584c5c-jmkls 1/1 Running 0 6m15s kubernetes-dashboard-79d9cd965-fcb4t 1/1 Running 0 6m14s 启动好后，仪表盘的在线访问地址为： https://2886795306-30000-ollie07.environments.katacoda.com/\n","date":"2021-07-20T10:21:00+08:00","image":"https://www.catfish.top/p/k8s-basic-1/kubernates_hu999cd8b4a0602898549f5ade1550b92a_32166_120x120_fill_box_smart1_2.png","permalink":"https://www.catfish.top/p/k8s-basic-1/","title":"Kubernetes初探（一）"},{"content":"介绍 Katacoda 是一个面向软件工程师的交互式学习和培训平台，可在浏览器中使用真实环境学习和测试新技术，帮助开发人员学习，并掌握最佳实践。\nKatacoda 的目标是消除新技术和技能的障碍。\nKatacoda 提供了一个平台来构建实时交互式演示和培训环境。运行环境可以根据应用要求进行定制。分步指导路径旨在确保用户以最佳方式学习。用户可以根据设计好的引导步骤，通过浏览器上的终端界面操作一套完整的环境，一步步的学习和实践。Katacoda 的出现很好的解决了这些问题。课程设计者可以定制应用程序所需环境，并设计循序渐进的指导路径，旨在确保用户以最佳方式学习。\nKatacoda 同样也是Kubernetes官网的学习工具，能够快速帮助开发者掌握K8s知识与应用，同时能够节省大量搭建部署环境的时间与精力，能够让开发者专注于学习掌握K8s。\nPlayground功能更是为开发者带来一种新的开发体验。借助于Katacoda平台，能够快速构建满足应用要求的各类环境，开发者能够在这之中，专注于完成创造、验证等工作。\n使用体验 课程 Playground 中文翻译-目录 Kubernetes Basic 原文：https://www.katacoda.com/courses/kubernetes\nLaunch A Single Node Cluster 原文：https://www.katacoda.com/courses/kubernetes/launch-single-node-cluster\n","date":"2021-07-19T17:57:00+08:00","image":"https://www.catfish.top/p/katacoda/katacoda_huf47240e26664e9c6e2f7130233d16c2d_114448_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.catfish.top/p/katacoda/","title":"Katacoda 在线学习神器"},{"content":"概述 Google工程师Jeffrey Dean 和 Sanjay Ghemawat在2004年发表了一篇论文MapReduce: Simplified Data Processing on Large Clusters，MapReduce作为大规模数据处理的需求下孕育而生的产物，被创造的初衷是为了解决Google公司内部搜索引擎中大规模数据的并行化处理。\n引用维基百科中对MapReduce的介绍：\n MapReduce是Google提出的一个软件架构，用于大规模数据集（大于1TB）的并行运算。\n 概念“Map（映射）”和“Reduce（归纳）”，及他们的主要思想，都是从函数式编程语言借来的，还有从矢量编程语言借来的特性。当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归纳）函数，用来保证所有映射的键值对中的每一个共享相同的键组。\n本系列将根据MIT6.824课程进行学习 MapReduce\n 简单看来，MapReduce的架构正如其名，分为Map和Reduce两部分。\n MapReduce Overview \n作为一个计算框架，其最大的核心便在于计算二字，以往处理计算的模式为单机运行，在大数据的情况下只能使用具有更强算力的计算机来完成计算工作，而算力的提升是需要花费极大的成本，这样在成本上是极为不划算的。在这一背景下MapReduce孕育而生，有个这样一个框架，就可以将数台不同算力的计算机组成一个集群，和适度的调度下并行计算提高效率降低成本。\n根据上图，MapReduce中存在3中角色，Master，Worker（Map），Worker(Reduce）,Master负责Map，Reduce两层的调度管理,Worker(Map)负责进行Map操作，Worker（Reduce）负责进行Reduce操作\n现在以该课程lab1为例来进行细致的学习，整套课程将由Go语言来实现。 lab1主要是对MapReduce模型进行初步的学习，实现一个本机的MapReduce模型，完成对多个文件的词频统计。\n示例程序流程 入口由上层程序控制，这个地方从master调度开始，预先定义Reduce任务个数m，再根据文本文件输入数量n。\nmaster将n传递给doMap也就是Map调度层，告诉Map调度层执行n次Map计算，每个Map计算层对应输入各个文本文件的数据。\nMap调度层将输出m*n个文件作为Map和Reduce的中间数据传递媒介，举例假设现在m为2、n为3，输出文件mid-0-0 mid-0-1 mid-1-0 mid-1-1 mid-2-0 mid-2-1这六个文件,其中mid-0-0 mid-0-1为第一个文本Map操作后的到的切分开的两个中间数据文件，剩下的以此类推。\n在Reduce调度层中便会将这六个文件交由Reduce计算层处理，将件mid-0-0 mid-1-0 mid-2-0交由编号为0的Reduce计算任务处理，显然，编号为1的任务则负责剩下3个文件的规约操作。Reduce调度层中仍然会将每个Reduce计算层任务得到的数据分别存入文件，根据Reduce任务的数量m为2，则文件编号分别为res-0 res-1，这样Map、Reduce两种操作完成，但整个任务还为完成。\nMerge操作则是最后一个步骤通常由master来完成，通过merge操作将上述的res-0 res-1合并，将所有结果存入到一个文件中，这样，整个MapReduce实现的多文本词频统计程序执行完毕。\n 数据结构 type KeyValue struct { Key string Value string } 实现 Master调度 master.go\nfunc (mr *Master) run(jobName string, files []string, nreduce int, schedule func(phase jobPhase), finish func(), ) { mr.jobName = jobName mr.files = files mr.nReduce = nreduce fmt.Printf(\u0026#34;%s: Starting Map/Reduce task %s\\n\u0026#34;, mr.address, mr.jobName) schedule(mapPhase) //map层进行操作 \tschedule(reducePhase) //reduce层进行操作 \tfinish() //结束所有worker \tmr.merge() //合并  fmt.Printf(\u0026#34;%s: Map/Reduce task completed\\n\u0026#34;, mr.address) mr.doneChannel \u0026lt;- true } 这部分展示了master如何对map、reduce进行调度的过程，首先执行所有的map操作，执行完毕后执行所有的reduce操作进行规约，最后merge合并所有reduce之后的结果，把所有的结果汇总并存储。\n Map调度层 common_map.go\nfunc doMap( jobName string, // MapReduce任务名 \tmapTaskNumber int, // Map任务序号 \tinFile string, nReduce int, // Reduce Worker数量 (\u0026#34;R\u0026#34; in the paper) \tmapF func(file string, contents string) []KeyValue, ) { dat, err := ioutil.ReadFile(inFile) //读文本文件 \tif err != nil { panic(err) } res := mapF(inFile, string(dat)) //根据文件中的内容进行单文件Map操作 \tm := make([]map[string]string, nReduce) //对于每个文本文件，将使用KeyValue的slice来存放，之后会对这部分数据进行切分，根据nReduce（reduce层worker数量）来决定划分数目 \tfor _, kv := range res { index := ihash(kv.Key) % nReduce //序号划分，根据Key做hash处理，对结果模你Reduce得到划分序号 \tif m[index] == nil{ m[index] = make(map[string]string) } m[index][kv.Key] = kv.Value } for i := 0; i \u0026lt; nReduce; i++ { filename := reduceName(jobName, mapTaskNumber, i) jsonObj, err := json.Marshal(m[i]) //使用json作为中间数据 \tif err != nil { panic(err) } ioutil.WriteFile(filename, jsonObj, 0644) //将数据写入到文件中 //将json数据写入到文件中，供Reduce操作使用 \t} Map调度层提供数据的输入与输出，不关心计算过程\n Map计算层 wc.go\n//filename 为输入文件文件名 //contents 为文本内容 func mapF(filename string, contents string) []mapreduce.KeyValue { var res []mapreduce.KeyValue m := make(map[string] int) reg := regexp.MustCompile(\u0026#34;\\n|\\r|\\t|[ ]+|[\\\\-]+|\\\\(|\\\\)\u0026#34;) contents = reg.ReplaceAllString(contents,\u0026#34; \u0026#34;) reg = regexp.MustCompile(\u0026#34;[^(a-zA-Z )]\u0026#34;) contents = reg.ReplaceAllString(contents,\u0026#34;\u0026#34;) //fmt.Println(contents) \ts := strings.Split(contents,\u0026#34; \u0026#34;) for i := 0;i \u0026lt; len(s);i++ { str := strings.TrimSpace(s[i]) m[strings.ToLower(str)]++ } for k,v := range m{ val := strconv.Itoa(v) res = append(res, mapreduce.KeyValue{k, val }) } fmt.Println(res) return res } Map计算层根据输入的文本内容完成下列步骤：\n 使用正则表达式将\\n \\t \\r替换为空格 使用正则表达式将无关字符删除 使用strings.Split方法根据空格进行划分 取出划分后的每个词，使用strings.TrimSpace方法去除两端空格，使用map[string] int结构的m来完成统计 将map[string] int转换为[]KeyValue返回  Map计算层和Map调度层共同组成的Map的结构，一个负责计算，一个负责IO，分工明确\n Reduce调度层 common_reduce.go\nfunc doReduce( jobName string, // MapReduce任务名 \treduceTaskNumber int, // Reduce任务序号 \toutFile string, // 输出文件路径 \tnMap int, // Map任务数 (\u0026#34;M\u0026#34; in the paper) \treduceF func(key string, values []string) string, ) { m := make(map[string][]string) for i := 0; i \u0026lt; nMap; i++ { filename := reduceName(jobName, i, reduceTaskNumber) fmt.Println(filename) data, err := ioutil.ReadFile(filename) if err != nil { panic(err) } var tm map[string]string err = json.Unmarshal(data, \u0026amp;tm) if err != nil { panic(err) } for k, v := range tm { if err != nil { panic(err) } m[k] = append(m[k], v) } } dataM := make([]KeyValue,0) for k, v := range m { ans := reduceF(k, v) dataM = append(dataM, KeyValue{k,ans}) } jsonData, err := json.Marshal(dataM) if err != nil { panic(err) } ioutil.WriteFile(outFile, jsonData, 0644) } Reduce调度层完成的工作是将Map执行后的文件读入为数据交有Reduce来规约，同样也不负责Reduce具体的过程，仅负责数据的读入（文件读入）和数据的保存（文件写出）\n Reduce计算层 wc.go\n//key为文本中的单词 //values为各个Map处理后得到的单词的个数 func reduceF(key string, values []string) string { sum :=0 for _,v := range values{ num,err := strconv.Atoi(v) //string转int \tif err!=nil{ panic(err) } sum+=num //累加 \t} return strconv.Itoa(sum) //将int转string返回 } Reduce计算层则仅仅负责数据的规约，步骤如下：\n 遍历整个values切片 将values的数值累加 将累加总和作为结果返回   Merge func (mr *Master) merge() { kvs := make(map[string]string) //总的数据存放 \tfor i := 0; i \u0026lt; mr.nReduce; i++ { p := mergeName(mr.jobName, i) //merge文件名生成 \tfile,err :=ioutil.ReadFile(p) if err != nil { log.Fatal(\u0026#34;Merge: \u0026#34;, err) } var jsonObj []KeyValue err = json.Unmarshal(file,\u0026amp;jsonObj) //json解码 \tif err != nil{ log.Fatal(\u0026#34;Merge: \u0026#34;, err) } for _,v:=range jsonObj{ kvs[v.Key] = v.Value } } } Merge操作便将Reduce操作得到的数据进行合并，完成最后一步工作。\n 总结 通过这几天短暂的学习，MapReduce模型确实能够极大的利用现有计算资源来打造一个算力强劲的计算机集群，但是本实例中也存在几个局限性：\n 本实例仅在单机中运行 操作间数据交换使用文件，在性能上可能会有一定影响 任务划分的科学性也应该是性能上应该考虑的问题，集群中计算机算力各不相同的时候，能者多劳，任务的划分应更加合理，才可能避免水桶原理造成的性能上的损失  如有不足之处，恳请提出批评！\n","date":"2017-09-07T01:21:00+08:00","image":"https://www.catfish.top/p/mit6.824-1/hadoop_hu7a934a9f3335148cadbaca544cf45563_202913_120x120_fill_box_smart1_2.png","permalink":"https://www.catfish.top/p/mit6.824-1/","title":"MIT 6.824 分布式系统初探（一）"},{"content":"字符编码 字集码是把字符集中的字符编码为指定集合中某一对象（例如：比特模式、自然数序列、8位组或者电脉冲），以便文本在计算机中存储和通过通信网络的传递。\n常见的例子包括将拉丁字母表编码成摩斯电码和ASCII。其中，ASCII将字母、数字和其它符号编号，并用7比特的二进制来表示这个整数。通常会额外使用一个扩充的比特，以便于以1个字节的方式存储。 常见的字符编码有： ASCII、UTF-8、Unicode、GBK等\n详见WikiPedia\n ASCII ASCII ( A merican S tandard C ode for I nformation I nterchange) 即美国信息交换标准代码。\nASCII第一次以规范标准的型态发表是在1967年，最后一次更新则是在1986年，至今为止共定义了128个字符；其中33个字符无法显示（一些终端提供了扩展，使得这些字符可显示为诸如笑脸、扑克牌花式等8-bit符号），且这33个字符多数都已是陈废的控制字符。控制字符的用途主要是用来操控已经处理过的文字。在33个字符之外的是95个可显示的字符，包含用键盘敲下空白键所产生的空白字符也算1个可显示字符（显示为空白）。\nASCII的局限在于只能显示26个基本拉丁字母、阿拉伯数目字和英式标点符号，因此只能用于显示现代美国英语（而且在处理英语当中的外来词如naïve、café、élite等等时，所有重音符号都不得不去掉，即使这样做会违反拼写规则）。而EASCII虽然解决了部分西欧语言的显示问题，但对更多其他语言依然无能为力。因此现在的软件系统大多采用Unicode。\n详见WikiPedia\n Unicode  Unicode 是为了解决传统的字符编码方案的局限而产生的，例如ISO 8859-1所定义的字符虽然在不同的国家中广泛地使用，可是在不同国家间却经常出现不兼容的情况。\n很多传统的编码方式都有一个共同的问题，即容许电脑处理双语环境（通常使用拉丁字母以及其本地语言），但却无法同时支持多语言环境（指可同时处理多种语言混合的情况）。\n目前，几乎所有电脑系统都支持基本拉丁字母，并各自支持不同的其他编码方式。Unicode为了和它们相互兼容，其首256字符保留给ISO 8859-1所定义的字符，使既有的西欧语系文字的转换不需特别考量；并且把大量相同的字符重复编到不同的字符码中去，使得旧有纷杂的编码方式得以和Unicode编码间互相直接转换，而不会丢失任何信息。举例来说，全角格式区块包含了主要的拉丁字母的全角格式，在中文、日文、以及韩文字形当中，这些字符以全角的方式来呈现，而不以常见的半角形式显示，这对竖排文字和等宽排列文字有重要作用。\n详见WikiPedia\n UTF-8  UTF-8 （8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字符编码，也是一种前缀码。\n它可以用来表示Unicode标准中的任何字符，且其编码中的第一个字节仍与ASCII兼容，这使得原来处理ASCII字符的软件无须或只须做少部分修改，即可继续使用。因此，它逐渐成为电子邮件、网页及其他存储或发送文字的应用中，优先采用的编码。\nUTF-8 现已经作为通用的字符编码，应用于各中网页编码，数据编码，数据库字符编码等。编码的统一能够写出的程序或网页在中文环境下大大减少乱码的出现。dddddddddddddddddd\n详见WikiPedia\n GBK  汉字内码扩展规范 ，称GBK，全名为《汉字内码扩展规范(GBK)》1.0版，由中华人民共和国全国信息技术标准化技术委员会1995年12月1日制订，国家技术监督局标准化司和电子工业部科技与质量监督司1995年12月15日联合以《技术标函[1995]229号》文件的形式公布。\nGBK的K为汉语拼音Kuo Zhan（扩展）中“扩”字的声母。英文全称Chinese Internal Code Extension Specification。\nGBK 只为“技术规范指导性文件”，不属于国家标准。国家质量技术监督局于2000年3月17日推出了GB 18030-2000标准，以取代GBK。\n BOM ( Byte Order Mark )  这个才是重点，BOM头。\n在UTF-8编码文件中BOM在文件头部，占用三个字节，用来标示该文件属于UTF-8编码，现在已经有很多软件识别BOM头，但是还有些不能识别BOM头，比如Windows自带的记事本软件，这也是用记事本编辑UTF-8编码后执行就会出错的原因了。\nWindows下\n  支持BOM的编辑器 Notepad++\n  不支持BOM的编辑器 Windows自带的记事本 （坑）\n  正因有BOM头的存在，使我在本地Jekyll的调试环境中，页面不能正常显示。\n请使用Windows的童鞋一定注意该问题\n目前已经切换为 Hugo + GitHub Action 的方式来完成静态网站的生成\n","date":"2016-05-18T00:36:00+08:00","image":"https://www.catfish.top/p/bom/bom_hu2fca0881760928b759bf10a8d0d84e1c_194611_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.catfish.top/p/bom/","title":"Blog 第一帖 - 字符坑 BOM"}]