[{"content":"Kubernetes初探（一） - 启动一个单节点集群  https://www.katacoda.com/courses/kubernetes/launch-single-node-cluster\n Minikube 是一个可以轻松在本地运行 Kubernetes 的工具。 Minikube 是一个在本地上计算机的虚拟机内运行一个单节点 Kubernetes 集群，便于用户能够完成日常开发工作，同时也能够让新用户快速了解Kubernetes。\n详情见： https://github.com/kubernetes/minikube\n步骤 1 - 启动Minikube Minikube已经安装并配置到环境中。通过运行 minikube version 命令检查它是否已正确安装。\n$ minikube version minikube version: v1.8.1 commit: cbda04cf6bbe65e987ae52bb393c10099ab62014 通过运行 minikube start 命令启动集群。\n$ minikube start --wait=false * minikube v1.8.1 on Ubuntu 18.04 * Using the none driver based on user configuration * Running on localhost (CPUs=2, Memory=2460MB, Disk=145651MB) ... * OS release is Ubuntu 18.04.4 LTS * Preparing Kubernetes v1.17.3 on Docker 19.03.6 ... - kubelet.resolv-conf=/run/systemd/resolve/resolv.conf * Launching Kubernetes ... * Enabling addons: default-storageclass, storage-provisioner * Configuring local host environment ... * Done! kubectl is now configured to use \u0026#34;minikube\u0026#34; 现在，您的在线终端中有一个正在运行的 Kubernetes 集群。 Minikube会启动一个虚拟机为K8S集群提供运行环境。\n步骤 2 - 集群信息 用户使用 kubectl 客户端与集群交互。该工具用于管理 Kubernetes 和在集群上运行的应用程序.\n通过kubectl cluster-info命令查看集群详情信息和健康状态。\n$ kubectl cluster-info Kubernetes master is running at https://172.17.0.10:8443 KubeDNS is running at https://172.17.0.10:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use \u0026#39;kubectl cluster-info dump\u0026#39;. 通过kubectl get nodes查看集群中的各节点信息。\n$ kubectl get nodes NAME STATUS ROLES AGE VERSION minikube Ready master 9m15s v1.17.3 如果节点被标记为 NotReady 则它仍在启动组件阶段。\n此命令显示可用于托管我们的应用程序的所有节点。现在我们只有一个节点，可以看到它的状态是Ready。\n步骤 3 - 部署容器 现在可以通过 Kubernetes 集群来部署容器。\nkubectl run命令能够将容器部署到集群中。\n$ kubectl create deployment first-deployment --image=katacoda/docker-http-server deployment.apps/first-deployment created 部署状态可以通过Pods的运行状态得知。\n$ kubectl get pods NAME READY STATUS RESTARTS AGE first-deployment-666c48b44-n7qjz 1/1 Running 0 60s 容器运行后，可以根据需求使用不同的网络选项公开暴露接口。其中的一种解决方案是 NodePort，它为容器提供动态端口。\n$ kubectl expose deployment first-deployment --port=80 --type=NodePort service/first-deployment exposed 下面的命令能够查询到绑定的端口，并且能够发送HTTP请求进行测试。\n$ export PORT=$(kubectl get svc first-deployment -o go-template=\u0026#39;{{range.spec.ports}}{{if .nodePort}}{{.nodePort}}{{\u0026#34;\\n\u0026#34;}}{{end}}{{end}}\u0026#39;) $ echo \u0026#34;Accessing host01:$PORT\u0026#34; Accessing host01:32492 $ curl host01:$PORT \u0026lt;h1\u0026gt;This request was processed by host: first-deployment-666c48b44-n7qjz\u0026lt;/h1\u0026gt; 结果显示的是处理请求的容器。\n步骤 4 - 仪表盘 使用 Minikube命令启用仪表板\n$ minikube addons enable dashboard * The \u0026#39;dashboard\u0026#39; addon is enabled 通过使用yaml文件来定义部署Kubernetes Dashboard。该配置仅适用于Katacoda\n/opt/kubernetes-dashboard.yaml\napiVersion:v1kind:Namespacemetadata:labels:addonmanager.kubernetes.io/mode:Reconcilekubernetes.io/minikube-addons:dashboardname:kubernetes-dashboardselfLink:/api/v1/namespaces/kubernetes-dashboardspec:finalizers:- kubernetesstatus:phase:Active---apiVersion:v1kind:Servicemetadata:labels:app:kubernetes-dashboardname:kubernetes-dashboard-katacodanamespace:kubernetes-dashboardspec:ports:- port:80protocol:TCPtargetPort:9090nodePort:30000selector:k8s-app:kubernetes-dashboardtype:NodePort$ kubectl apply -f /opt/kubernetes-dashboard.yaml namespace/kubernetes-dashboard configured service/kubernetes-dashboard-katacoda created 可以使用Kubernetes仪表板查看部署到集群中的应用程序。仪表板将部署在 30000 端口，但需要一段时间才能完成启动。\n要查看 Dashboard启动的进度，请使用 kubectl get pods -n kubernetes-dashboard -w 查看 kube-system命名空间中的 Pod\n$ kubectl get pods -n kubernetes-dashboard -w NAME READY STATUS RESTARTS AGE dashboard-metrics-scraper-7b64584c5c-jmkls 1/1 Running 0 6m15s kubernetes-dashboard-79d9cd965-fcb4t 1/1 Running 0 6m14s 启动好后，仪表盘的在线访问地址为： https://2886795306-30000-ollie07.environments.katacoda.com/\n","date":"2021-07-20T10:21:00+08:00","image":"https://www.catfish.top/p/k8s-basic-1/kubernetes-horizontal-color_hu999cd8b4a0602898549f5ade1550b92a_32166_120x120_fill_box_smart1_2.png","permalink":"https://www.catfish.top/p/k8s-basic-1/","title":"Kubernetes初探（一） - 启动一个单节点集群"},{"content":"介绍 Katacoda 是一个面向软件工程师的交互式学习和培训平台，可在浏览器中使用真实环境学习和测试新技术，帮助开发人员学习，并掌握最佳实践。\nKatacoda 的目标是消除新技术和技能的障碍。\nKatacoda 提供了一个平台来构建实时交互式演示和培训环境。运行环境可以根据应用要求进行定制。分步指导路径旨在确保用户以最佳方式学习。用户可以根据设计好的引导步骤，通过浏览器上的终端界面操作一套完整的环境，一步步的学习和实践。Katacoda 的出现很好的解决了这些问题。课程设计者可以定制应用程序所需环境，并设计循序渐进的指导路径，旨在确保用户以最佳方式学习。\nKatacoda 同样也是Kubernetes官网的学习工具，能够快速帮助开发者掌握K8s知识与应用，同时能够节省大量搭建部署环境的时间与精力，能够让开发者专注于学习掌握K8s。\nPlayground功能更是为开发者带来一种新的开发体验。借助于Katacoda平台，能够快速构建满足应用要求的各类环境，开发者能够在这之中，专注于完成创造、验证等工作。\n使用体验 课程 Playground 中文翻译-目录 Kubernetes Basic 原文：https://www.katacoda.com/courses/kubernetes\nLaunch A Single Node Cluster 原文：https://www.katacoda.com/courses/kubernetes/launch-single-node-cluster\n","date":"2021-07-19T17:57:00+08:00","image":"https://www.catfish.top/p/katacoda/katacoda_huf47240e26664e9c6e2f7130233d16c2d_114448_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.catfish.top/p/katacoda/","title":"Katacoda 在线学习神器"},{"content":"概述 Google工程师Jeffrey Dean 和 Sanjay Ghemawat在2004年发表了一篇论文MapReduce: Simplified Data Processing on Large Clusters，MapReduce作为大规模数据处理的需求下孕育而生的产物，被创造的初衷是为了解决Google公司内部搜索引擎中大规模数据的并行化处理。\n引用维基百科中对MapReduce的介绍：\n MapReduce是Google提出的一个软件架构，用于大规模数据集（大于1TB）的并行运算。\n 概念“Map（映射）”和“Reduce（归纳）”，及他们的主要思想，都是从函数式编程语言借来的，还有从矢量编程语言借来的特性。当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归纳）函数，用来保证所有映射的键值对中的每一个共享相同的键组。\n本系列将根据MIT6.824课程进行学习 MapReduce\n 简单看来，MapReduce的架构正如其名，分为Map和Reduce两部分。\n MapReduce Overview \n作为一个计算框架，其最大的核心便在于计算二字，以往处理计算的模式为单机运行，在大数据的情况下只能使用具有更强算力的计算机来完成计算工作，而算力的提升是需要花费极大的成本，这样在成本上是极为不划算的。在这一背景下MapReduce孕育而生，有个这样一个框架，就可以将数台不同算力的计算机组成一个集群，和适度的调度下并行计算提高效率降低成本。\n根据上图，MapReduce中存在3中角色，Master，Worker（Map），Worker(Reduce）,Master负责Map，Reduce两层的调度管理,Worker(Map)负责进行Map操作，Worker（Reduce）负责进行Reduce操作\n现在以该课程lab1为例来进行细致的学习，整套课程将由Go语言来实现。 lab1主要是对MapReduce模型进行初步的学习，实现一个本机的MapReduce模型，完成对多个文件的词频统计。\n示例程序流程 入口由上层程序控制，这个地方从master调度开始，预先定义Reduce任务个数m，再根据文本文件输入数量n。\nmaster将n传递给doMap也就是Map调度层，告诉Map调度层执行n次Map计算，每个Map计算层对应输入各个文本文件的数据。\nMap调度层将输出m*n个文件作为Map和Reduce的中间数据传递媒介，举例假设现在m为2、n为3，输出文件mid-0-0 mid-0-1 mid-1-0 mid-1-1 mid-2-0 mid-2-1这六个文件,其中mid-0-0 mid-0-1为第一个文本Map操作后的到的切分开的两个中间数据文件，剩下的以此类推。\n在Reduce调度层中便会将这六个文件交由Reduce计算层处理，将件mid-0-0 mid-1-0 mid-2-0交由编号为0的Reduce计算任务处理，显然，编号为1的任务则负责剩下3个文件的规约操作。Reduce调度层中仍然会将每个Reduce计算层任务得到的数据分别存入文件，根据Reduce任务的数量m为2，则文件编号分别为res-0 res-1，这样Map、Reduce两种操作完成，但整个任务还为完成。\nMerge操作则是最后一个步骤通常由master来完成，通过merge操作将上述的res-0 res-1合并，将所有结果存入到一个文件中，这样，整个MapReduce实现的多文本词频统计程序执行完毕。\n 数据结构 type KeyValue struct { Key string Value string } 实现 Master调度 master.go\nfunc (mr *Master) run(jobName string, files []string, nreduce int, schedule func(phase jobPhase), finish func(), ) { mr.jobName = jobName mr.files = files mr.nReduce = nreduce fmt.Printf(\u0026#34;%s: Starting Map/Reduce task %s\\n\u0026#34;, mr.address, mr.jobName) schedule(mapPhase) //map层进行操作 \tschedule(reducePhase) //reduce层进行操作 \tfinish() //结束所有worker \tmr.merge() //合并  fmt.Printf(\u0026#34;%s: Map/Reduce task completed\\n\u0026#34;, mr.address) mr.doneChannel \u0026lt;- true } 这部分展示了master如何对map、reduce进行调度的过程，首先执行所有的map操作，执行完毕后执行所有的reduce操作进行规约，最后merge合并所有reduce之后的结果，把所有的结果汇总并存储。\n Map调度层 common_map.go\nfunc doMap( jobName string, // MapReduce任务名 \tmapTaskNumber int, // Map任务序号 \tinFile string, nReduce int, // Reduce Worker数量 (\u0026#34;R\u0026#34; in the paper) \tmapF func(file string, contents string) []KeyValue, ) { dat, err := ioutil.ReadFile(inFile) //读文本文件 \tif err != nil { panic(err) } res := mapF(inFile, string(dat)) //根据文件中的内容进行单文件Map操作 \tm := make([]map[string]string, nReduce) //对于每个文本文件，将使用KeyValue的slice来存放，之后会对这部分数据进行切分，根据nReduce（reduce层worker数量）来决定划分数目 \tfor _, kv := range res { index := ihash(kv.Key) % nReduce //序号划分，根据Key做hash处理，对结果模你Reduce得到划分序号 \tif m[index] == nil{ m[index] = make(map[string]string) } m[index][kv.Key] = kv.Value } for i := 0; i \u0026lt; nReduce; i++ { filename := reduceName(jobName, mapTaskNumber, i) jsonObj, err := json.Marshal(m[i]) //使用json作为中间数据 \tif err != nil { panic(err) } ioutil.WriteFile(filename, jsonObj, 0644) //将数据写入到文件中 //将json数据写入到文件中，供Reduce操作使用 \t} Map调度层提供数据的输入与输出，不关心计算过程\n Map计算层 wc.go\n//filename 为输入文件文件名 //contents 为文本内容 func mapF(filename string, contents string) []mapreduce.KeyValue { var res []mapreduce.KeyValue m := make(map[string] int) reg := regexp.MustCompile(\u0026#34;\\n|\\r|\\t|[ ]+|[\\\\-]+|\\\\(|\\\\)\u0026#34;) contents = reg.ReplaceAllString(contents,\u0026#34; \u0026#34;) reg = regexp.MustCompile(\u0026#34;[^(a-zA-Z )]\u0026#34;) contents = reg.ReplaceAllString(contents,\u0026#34;\u0026#34;) //fmt.Println(contents) \ts := strings.Split(contents,\u0026#34; \u0026#34;) for i := 0;i \u0026lt; len(s);i++ { str := strings.TrimSpace(s[i]) m[strings.ToLower(str)]++ } for k,v := range m{ val := strconv.Itoa(v) res = append(res, mapreduce.KeyValue{k, val }) } fmt.Println(res) return res } Map计算层根据输入的文本内容完成下列步骤：\n 使用正则表达式将\\n \\t \\r替换为空格 使用正则表达式将无关字符删除 使用strings.Split方法根据空格进行划分 取出划分后的每个词，使用strings.TrimSpace方法去除两端空格，使用map[string] int结构的m来完成统计 将map[string] int转换为[]KeyValue返回  Map计算层和Map调度层共同组成的Map的结构，一个负责计算，一个负责IO，分工明确\n Reduce调度层 common_reduce.go\nfunc doReduce( jobName string, // MapReduce任务名 \treduceTaskNumber int, // Reduce任务序号 \toutFile string, // 输出文件路径 \tnMap int, // Map任务数 (\u0026#34;M\u0026#34; in the paper) \treduceF func(key string, values []string) string, ) { m := make(map[string][]string) for i := 0; i \u0026lt; nMap; i++ { filename := reduceName(jobName, i, reduceTaskNumber) fmt.Println(filename) data, err := ioutil.ReadFile(filename) if err != nil { panic(err) } var tm map[string]string err = json.Unmarshal(data, \u0026amp;tm) if err != nil { panic(err) } for k, v := range tm { if err != nil { panic(err) } m[k] = append(m[k], v) } } dataM := make([]KeyValue,0) for k, v := range m { ans := reduceF(k, v) dataM = append(dataM, KeyValue{k,ans}) } jsonData, err := json.Marshal(dataM) if err != nil { panic(err) } ioutil.WriteFile(outFile, jsonData, 0644) } Reduce调度层完成的工作是将Map执行后的文件读入为数据交有Reduce来规约，同样也不负责Reduce具体的过程，仅负责数据的读入（文件读入）和数据的保存（文件写出）\n Reduce计算层 wc.go\n//key为文本中的单词 //values为各个Map处理后得到的单词的个数 func reduceF(key string, values []string) string { sum :=0 for _,v := range values{ num,err := strconv.Atoi(v) //string转int \tif err!=nil{ panic(err) } sum+=num //累加 \t} return strconv.Itoa(sum) //将int转string返回 } Reduce计算层则仅仅负责数据的规约，步骤如下：\n 遍历整个values切片 将values的数值累加 将累加总和作为结果返回   Merge func (mr *Master) merge() { kvs := make(map[string]string) //总的数据存放 \tfor i := 0; i \u0026lt; mr.nReduce; i++ { p := mergeName(mr.jobName, i) //merge文件名生成 \tfile,err :=ioutil.ReadFile(p) if err != nil { log.Fatal(\u0026#34;Merge: \u0026#34;, err) } var jsonObj []KeyValue err = json.Unmarshal(file,\u0026amp;jsonObj) //json解码 \tif err != nil{ log.Fatal(\u0026#34;Merge: \u0026#34;, err) } for _,v:=range jsonObj{ kvs[v.Key] = v.Value } } } Merge操作便将Reduce操作得到的数据进行合并，完成最后一步工作。\n 总结 通过这几天短暂的学习，MapReduce模型确实能够极大的利用现有计算资源来打造一个算力强劲的计算机集群，但是本实例中也存在几个局限性：\n 本实例仅在单机中运行 操作间数据交换使用文件，在性能上可能会有一定影响 任务划分的科学性也应该是性能上应该考虑的问题，集群中计算机算力各不相同的时候，能者多劳，任务的划分应更加合理，才可能避免水桶原理造成的性能上的损失  如有不足之处，恳请提出批评！\n","date":"2017-09-07T01:21:00+08:00","image":"https://www.catfish.top/p/mit6.824-1/hadoop_hu7a934a9f3335148cadbaca544cf45563_202913_120x120_fill_box_smart1_2.png","permalink":"https://www.catfish.top/p/mit6.824-1/","title":"MIT 6.824 分布式系统初探（一）"},{"content":"字符编码 字集码是把字符集中的字符编码为指定集合中某一对象（例如：比特模式、自然数序列、8位组或者电脉冲），以便文本在计算机中存储和通过通信网络的传递。\n常见的例子包括将拉丁字母表编码成摩斯电码和ASCII。其中，ASCII将字母、数字和其它符号编号，并用7比特的二进制来表示这个整数。通常会额外使用一个扩充的比特，以便于以1个字节的方式存储。 常见的字符编码有： ASCII、UTF-8、Unicode、GBK等\n详见WikiPedia\n ASCII ASCII ( A merican S tandard C ode for I nformation I nterchange) 即美国信息交换标准代码。\nASCII第一次以规范标准的型态发表是在1967年，最后一次更新则是在1986年，至今为止共定义了128个字符；其中33个字符无法显示（一些终端提供了扩展，使得这些字符可显示为诸如笑脸、扑克牌花式等8-bit符号），且这33个字符多数都已是陈废的控制字符。控制字符的用途主要是用来操控已经处理过的文字。在33个字符之外的是95个可显示的字符，包含用键盘敲下空白键所产生的空白字符也算1个可显示字符（显示为空白）。\nASCII的局限在于只能显示26个基本拉丁字母、阿拉伯数目字和英式标点符号，因此只能用于显示现代美国英语（而且在处理英语当中的外来词如naïve、café、élite等等时，所有重音符号都不得不去掉，即使这样做会违反拼写规则）。而EASCII虽然解决了部分西欧语言的显示问题，但对更多其他语言依然无能为力。因此现在的软件系统大多采用Unicode。\n详见WikiPedia\n Unicode  Unicode 是为了解决传统的字符编码方案的局限而产生的，例如ISO 8859-1所定义的字符虽然在不同的国家中广泛地使用，可是在不同国家间却经常出现不兼容的情况。\n很多传统的编码方式都有一个共同的问题，即容许电脑处理双语环境（通常使用拉丁字母以及其本地语言），但却无法同时支持多语言环境（指可同时处理多种语言混合的情况）。\n目前，几乎所有电脑系统都支持基本拉丁字母，并各自支持不同的其他编码方式。Unicode为了和它们相互兼容，其首256字符保留给ISO 8859-1所定义的字符，使既有的西欧语系文字的转换不需特别考量；并且把大量相同的字符重复编到不同的字符码中去，使得旧有纷杂的编码方式得以和Unicode编码间互相直接转换，而不会丢失任何信息。举例来说，全角格式区块包含了主要的拉丁字母的全角格式，在中文、日文、以及韩文字形当中，这些字符以全角的方式来呈现，而不以常见的半角形式显示，这对竖排文字和等宽排列文字有重要作用。\n详见WikiPedia\n UTF-8  UTF-8 （8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字符编码，也是一种前缀码。\n它可以用来表示Unicode标准中的任何字符，且其编码中的第一个字节仍与ASCII兼容，这使得原来处理ASCII字符的软件无须或只须做少部分修改，即可继续使用。因此，它逐渐成为电子邮件、网页及其他存储或发送文字的应用中，优先采用的编码。\nUTF-8 现已经作为通用的字符编码，应用于各中网页编码，数据编码，数据库字符编码等。编码的统一能够写出的程序或网页在中文环境下大大减少乱码的出现。dddddddddddddddddd\n详见WikiPedia\n GBK  汉字内码扩展规范 ，称GBK，全名为《汉字内码扩展规范(GBK)》1.0版，由中华人民共和国全国信息技术标准化技术委员会1995年12月1日制订，国家技术监督局标准化司和电子工业部科技与质量监督司1995年12月15日联合以《技术标函[1995]229号》文件的形式公布。\nGBK的K为汉语拼音Kuo Zhan（扩展）中“扩”字的声母。英文全称Chinese Internal Code Extension Specification。\nGBK 只为“技术规范指导性文件”，不属于国家标准。国家质量技术监督局于2000年3月17日推出了GB 18030-2000标准，以取代GBK。\n BOM ( Byte Order Mark )  这个才是重点，BOM头。\n在UTF-8编码文件中BOM在文件头部，占用三个字节，用来标示该文件属于UTF-8编码，现在已经有很多软件识别BOM头，但是还有些不能识别BOM头，比如Windows自带的记事本软件，这也是用记事本编辑UTF-8编码后执行就会出错的原因了。\nWindows下\n  支持BOM的编辑器 Notepad++\n  不支持BOM的编辑器 Windows自带的记事本 （坑）\n  正因有BOM头的存在，使我在本地Jekyll的调试环境中，页面不能正常显示。\n请使用Windows的童鞋一定注意该问题\n目前已经切换为 Hugo + GitHub Action 的方式来完成静态网站的生成\n","date":"2016-05-18T00:36:00+08:00","image":"https://www.catfish.top/p/bom/bom_hu2fca0881760928b759bf10a8d0d84e1c_194611_120x120_fill_q75_box_smart1.jpg","permalink":"https://www.catfish.top/p/bom/","title":"Blog 第一帖 - 字符坑 BOM"}]